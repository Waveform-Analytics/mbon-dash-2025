# Data Structure

How data is organized in the project - from raw files to dashboard-ready datasets.

## Overview

```
data/                          # ðŸš« Git-ignored (CDN-based)
â”œâ”€â”€ cdn/                      # Mirror of cloud storage
â”‚   â”œâ”€â”€ raw-data/            # Excel files downloaded from CDN
â”‚   â””â”€â”€ processed/           # Dashboard JSON files (upload to CDN)
â””â”€â”€ intermediate_results/     # Your analysis workspace

scripts/                      # âœ… Version controlled
â”œâ”€â”€ dashboard_prep/          # Production data processing
â”œâ”€â”€ exploratory/             # Your analysis experiments
â”œâ”€â”€ utils/                   # Data validation tools
â””â”€â”€ data_management/         # CDN sync operations
```

!!! tip "CDN-First Approach"
    All data lives on cloud storage. Local folders mirror the CDN structure and are regenerated as needed.

## Raw Data Format

Downloaded to `data/cdn/raw-data/` from cloud storage:

### Species Detection Files
```
2018/Master_Manual_[STATION]_2h_2018.xlsx
2021/Master_Manual_[STATION]_2h_2021.xlsx
```
- **Stations**: 9M, 14M, 37M
- **Windows**: 2-hour detection periods
- **Content**: Manual species annotations (~28 species)

### Environmental Files
```
2018/Master_[STATION]_Temp_2018.xlsx
2018/Master_[STATION]_Depth_2018.xlsx
```
- **Measurements**: Temperature and depth
- **Resolution**: Higher frequency than detection data
- **Purpose**: Environmental context for analysis

### Acoustic Index Files *(Planned)*
```
indices/raw/Acoustic_Indices_9m_FullBW_v1.csv
```
- **Content**: 56 acoustic indices per hour
- **Integration**: Future development priority

### Metadata
```
1_Montie Lab_metadata_deployments_2017 to 2022.xlsx
```
- Station coordinates and deployment details

## Processed Data

Generated by `npm run process-data` â†’ `data/cdn/processed/`:

```
detections.json          # 26,280 species detection records
environmental.json       # 237,334 temperature/depth measurements  
deployment_metadata.json # 25 deployment records (filtered)
stations.json           # 3 station definitions
species.json            # 28 species with detection counts
metadata.json           # Processing summary and statistics
```

**Purpose**: Dashboard-ready data uploaded to CDN for web access.

## Data Pipeline

```bash
# Download raw data from CDN
npm run download-data

# Process Excel â†’ JSON for dashboard
npm run process-data

# Validate output quality
npm run validate-data

# View data summary
npm run data-stats
```

## Working with Data

### For Dashboard Development
Use processed JSON files in `data/cdn/processed/` - optimized for web loading.

### For Analysis
Load JSON into pandas for custom analysis:

```python
import pandas as pd
import json

# Load dashboard data
with open('data/cdn/processed/detections.json', 'r') as f:
    detections = pd.DataFrame(json.load(f))

# Your analysis here
```

### For Exploration
Save intermediate results to `data/intermediate_results/` to keep analysis organized.

## Key Datasets

| Dataset | Records | Purpose |
|---------|---------|---------|
| **Species Detections** | 26,280 | Primary - manual annotations |
| **Environmental** | 237,334 | Context - temp/depth patterns |
| **Deployment Metadata** | 25 | Background - station info |

**Scope**: 3 stations (9M, 14M, 37M) Ã— 2 years (2018, 2021) Ã— 28 species

This structure supports both dashboard visualization and custom scientific analysis while keeping data management simple and reproducible.
# View-Based Architecture Migration Plan

## Quick Start - Risk-Minimized Approach

This plan uses **Test-Driven Development (TDD)** with manual checkpoints to ensure zero-risk migration:

1. **Write tests first** â†’ 2. **Implement minimal code** â†’ 3. **Manual testing** â†’ 4. **Full implementation**

Each phase has:
- âœ… Checkboxes to track progress
- ðŸ§ª Automated tests to write before coding
- ðŸ‘€ Manual testing checkpoints with specific things to verify  
- âš ï¸ Clear rollback triggers if anything goes wrong

**Start here:** [Phase 1: Foundation Setup](#phase-1-foundation-setup-low-risk)

## Overview

Migrate from large monolithic JSON files to view-specific optimized data files with full CDN automation.

## Goals

- âœ… **Zero risk refactoring** - keep existing system working during migration
- âœ… **Test-driven development** - write tests before implementation
- âœ… **Manual testing checkpoints** - verify each step works correctly
- âœ… **Clean Python package architecture** - all logic in `mbon_analysis`, scripts are thin wrappers
- âœ… **Fully automated CDN pipeline** - one command to prep, upload, and validate
- âœ… **Interactive dashboard features preserved** - filtering, zoom, hover, etc.
- âœ… **Developer-friendly** - easy to "jump back in" after months
- âœ… **Clear exploration workflow** - separate local exploration from production pipeline
- âœ… **Project-agnostic design** - code should work for any marine monitoring project (any number of stations, any naming)

## Exploration vs. Pipeline Workflow

### **Local Exploration (Development Phase)**
- Use Marimo notebooks, Python scripts, or exploratory analysis in `scripts/exploratory/`
- Load data using `mbon_analysis` package functions for interactive exploration
- Experiment with different visualizations, aggregations, and analyses
- Prototype charts and identify what data views are needed

### **Production Pipeline (Dashboard Integration)**
- Once you decide on a specific plot/visualization, add it to the formal pipeline
- Create view generator in `mbon_analysis/views/` that produces the exact data structure needed
- Add corresponding frontend page that loads the optimized view data
- Deploy via automated CDN pipeline

### **Clear Separation:**
```
Local Exploration:    Raw Data â†’ mbon_analysis functions â†’ Interactive exploration
Production Pipeline:  Raw Data â†’ mbon_analysis/views â†’ Optimized JSON â†’ CDN â†’ Dashboard
```

This keeps exploration flexible while ensuring the production system is clean and optimized.

## Current State Issues

1. **Performance**: 159MB acoustic_indices.json, 45MB environmental.json (despite recent pagination optimization)
2. **Manual CDN uploads**: Error-prone, tedious
3. **Complex pagination system**: 61 paginated files, complex pagination logic, still loading large amounts of data
4. **Maintenance burden**: Multiple systems, manual processes
5. **Architecture mismatch**: Frontend loads raw data instead of view-optimized data

## Target Architecture

### **Data Flow**
```
Excel Files â†’ mbon_analysis Package â†’ View-Specific JSONs â†’ Automated CDN â†’ Frontend
```

### **View-Specific Files (Small & Fast)**
- `station_overview.json` (~5KB) - Station locations, metadata, summary stats
- `species_timeline.json` (~100KB) - Monthly/yearly aggregated detection data
- `acoustic_summary.json` (~50KB) - Key acoustic indices, PCA results
- `environmental_trends.json` (~20KB) - Temperature/depth patterns
- `biodiversity_patterns.json` (~30KB) - Species co-occurrence, diversity metrics

### **Package Architecture**
```
mbon_analysis/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ excel_processor.py          # â† Existing (keep)
â”‚   â”œâ”€â”€ data_loader.py              # â† Existing (keep)  
â”‚   â””â”€â”€ view_generator.py           # â† NEW - core view generation logic
â”œâ”€â”€ views/                          # â† NEW module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ station_views.py            # â† Station-specific data processing
â”‚   â”œâ”€â”€ species_views.py            # â† Species timeline & analysis
â”‚   â”œâ”€â”€ acoustic_views.py           # â† Acoustic indices & PCA
â”‚   â”œâ”€â”€ environmental_views.py      # â† Temperature/depth trends
â”‚   â””â”€â”€ biodiversity_views.py       # â† Diversity metrics & patterns
â”œâ”€â”€ deployment/                     # â† NEW module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cdn_sync.py                 # â† Smart CDN upload logic
â”‚   â”œâ”€â”€ manifest_generator.py       # â† Auto-generate manifests
â”‚   â””â”€â”€ validation.py               # â† Deployment validation
â””â”€â”€ analysis/                       # â† Existing (keep)
    â””â”€â”€ ...
```

---

## Risk-Minimized Implementation Strategy

### **Test-Driven Development (TDD) Approach**
We'll follow a strict TDD methodology to minimize risk at each stage:
1. **Write tests first** - Define expected behavior before implementation
2. **Implement minimal code** - Just enough to pass tests
3. **Manual testing checkpoint** - Verify in browser after each stage
4. **Rollback trigger** - If any test fails, stop and fix before proceeding

### **Testing Infrastructure Setup**

#### **Prerequisites Checklist**
- [x] Add pytest to project: `uv add pytest pytest-cov`
- [x] Create test directories: `tests/unit/` and `tests/integration/`
- [x] Set up test fixtures for mock data
- [x] Configure pytest.ini for test discovery
- [x] Add test commands to package.json

---

## Phase 1: Foundation Setup (Low Risk)

### **1.1 Test Infrastructure Setup**

#### **Step 1.1.1: Install Testing Dependencies**
- [x] Run: `uv add pytest pytest-cov pytest-mock`
- [x] Run: `uv add --dev pytest-watch` (for continuous testing)
- [x] Verify installation: `uv run pytest --version`

#### **Step 1.1.2: Create Test Structure**
```bash
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_station_views.py      # Station view generator tests
â”‚   â”œâ”€â”€ test_cdn_sync.py          # CDN sync logic tests
â”‚   â””â”€â”€ test_view_generator.py    # Core view generation tests
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_end_to_end.py        # Full pipeline tests
â”‚   â””â”€â”€ test_cdn_deployment.py    # CDN deployment tests
â””â”€â”€ fixtures/
    â”œâ”€â”€ sample_data.py             # Sample test data
    â””â”€â”€ mock_responses.py          # Mock CDN responses
```
- [x] Create all test directories
- [x] Create placeholder test files
- [x] **MANUAL TEST**: Run `uv run pytest` - should find 0 tests but no errors

### **1.2 Create First Function with TDD**

#### **Step 1.2.1: Write Tests for `generate_station_overview()`**
```python
# tests/unit/test_station_views.py
def test_generate_station_overview_structure():
    """Test that station overview has correct structure."""
    result = generate_station_overview(mock_data_dir)
    assert 'stations' in result
    assert 'metadata' in result
    assert len(result['stations']) >= 0  # Can handle any number of stations

def test_station_overview_size():
    """Test that output is reasonably sized for performance."""
    result = generate_station_overview(mock_data_dir)
    json_str = json.dumps(result)
    station_count = len(result['stations'])
    size_limit = 5120 + station_count * 2048  # 5KB base + 2KB per station
    assert len(json_str) < size_limit

def test_station_summary_stats():
    """Test that each station has required summary stats."""
    result = generate_station_overview(mock_data_dir)
    for station in result['stations']:
        assert 'total_detections' in station['summary_stats']
        assert 'species_count' in station['summary_stats']

def test_station_coordinates():
    """Test that coordinates are valid lat/lon values."""
    result = generate_station_overview(mock_data_dir)
    for station in result['stations']:
        assert -90.0 <= station['coordinates']['lat'] <= 90.0
        assert -180.0 <= station['coordinates']['lon'] <= 180.0
```
- [x] Write all tests in `test_station_views.py` *(Updated: Made tests completely generic for any marine monitoring project - no hardcoded station names/counts)*
- [x] Run tests: `uv run pytest tests/unit/test_station_views.py -v`
- [x] Verify all tests FAIL (no implementation yet)

#### **Step 1.2.2: Implement Minimal `generate_station_overview()`**
```python
# mbon_analysis/views/station_views.py
def generate_station_overview(processed_data_dir: Path) -> dict:
    """Generate station overview optimized for interactive map."""
    # Minimal implementation to pass tests
    return {
        'stations': [],
        'metadata': {
            'generated_at': '2024-01-01T12:00:00Z',
            'data_sources': [],
            'total_stations': 0
        }
    }
```
- [x] Create `mbon_analysis/views/__init__.py`
- [x] Create `mbon_analysis/views/station_views.py`
- [x] Implement minimal function
- [x] Run tests: `uv run pytest tests/unit/test_station_views.py -v`
- [x] All tests PASS (excellent! Generic tests handle minimal case)

#### **Step 1.2.3: Full Implementation**
- [x] Implement complete `generate_station_overview()` function
- [x] Run tests: `uv run pytest tests/unit/test_station_views.py -v`
- [x] ALL tests should PASS
- [x] **MANUAL TEST CHECKPOINT**: 
  - [x] Run: `uv run python -c "from mbon_analysis.views import station_views; print(station_views.generate_station_overview('data/cdn/processed'))"`
  - [x] Verify output looks correct *(âœ… Real data: 3 stations, deployments, coordinates, stats)*
  - [x] Check file size is < 10KB *(âœ… 2.8 KB - excellent performance)*

**âš ï¸ ROLLBACK TRIGGER**: If any test fails or manual check shows issues, STOP and fix before proceeding

### **1.3 Script Wrapper Implementation**

#### **Step 1.3.1: Create Thin Wrapper Script**
```python
# scripts/view_generation/generate_station_views.py
#!/usr/bin/env python3
"""Thin wrapper to generate station views."""
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from mbon_analysis.views.station_views import generate_station_overview
import json

def main():
    data = generate_station_overview(Path('data/cdn/processed'))
    output_path = Path('data/cdn/views/station_overview.json')
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w') as f:
        json.dump(data, f, indent=2)
    
    print(f"âœ… Generated {output_path} ({len(json.dumps(data))} bytes)")

if __name__ == "__main__":
    main()
```
- [x] Create `scripts/view_generation/` directory
- [x] Create `generate_station_views.py` wrapper
- [x] Make script executable: `chmod +x scripts/view_generation/generate_station_views.py`
- [x] Test script: `uv run scripts/view_generation/generate_station_views.py`
- [x] Verify `data/cdn/views/station_overview.json` was created
- [x] **MANUAL TEST CHECKPOINT**:
  - [x] Check file size: `ls -lh data/cdn/views/station_overview.json` *(âœ… 4.5K - excellent)*
  - [x] Verify < 10KB *(âœ… Well under limit)*
  - [x] Open file and verify structure looks correct *(âœ… 3 stations, deployments, coordinates, stats, metadata)*

**âš ï¸ ROLLBACK TRIGGER**: If script fails or output is > 10KB, investigate before proceeding

### **1.4 New Directory Structure Setup**

#### **Step 1.4.1: Create Directory Structure**
```bash
# Keep existing structure intact
data/cdn/
â”œâ”€â”€ processed/          # â† DO NOT TOUCH (existing system)
â”‚   â”œâ”€â”€ detections.json
â”‚   â”œâ”€â”€ acoustic_indices.json
â”‚   â””â”€â”€ paginated/
â””â”€â”€ views/              # â† NEW (safe to add)
    â””â”€â”€ station_overview.json  # Created by script above
```
- [x] Verify `data/cdn/processed/` exists and is untouched *(âœ… Original system intact)*
- [x] Verify `data/cdn/views/` was created by the script *(âœ… Created with station_overview.json)*
- [ ] Add `data/cdn/views/` to `.gitignore` *(Optional - view files could be committed or ignored)*

---

## Phase 2: Build First View (Stations) - WITH TESTING

### **2.1 Frontend Hook Implementation**

#### **Step 2.1.1: Write Tests for Frontend Hook**
```typescript
// tests/unit/test_view_hooks.spec.tsx
describe('useViewData Hook', () => {
  it('should load station overview data successfully', async () => {
    const mockStationData = { stations: [...], metadata: {...} }
    fetch.mockResolvedValueOnce({ ok: true, json: async () => mockStationData })
    
    const { result } = renderHook(() => useViewData('station-overview'))
    
    await waitFor(() => expect(result.current.loading).toBe(false))
    expect(result.current.data).toEqual(mockStationData)
    expect(fetch).toHaveBeenCalledWith(`${process.env.NEXT_PUBLIC_DATA_URL}/views/station_overview.json`)
  });
  // ... comprehensive test suite covering loading, errors, type safety
});
```
- [x] Install React Testing Library: `npm install -D @testing-library/react @testing-library/jest-dom jest jest-environment-jsdom`
- [x] Create Jest configuration files (`jest.config.js`, `jest.setup.js`)
- [x] Create comprehensive tests in `tests/unit/test_view_hooks.spec.tsx`
- [x] Tests cover: loading states, error handling, type safety, view type validation
- [x] Run tests: `npm test` *(âœ… ALL 9 TESTS PASS)*

#### **Step 2.1.2: Implement `useViewData` Hook**
```typescript
// src/lib/hooks/useViewData.ts
export function useViewData<T extends ViewType>(viewType: T): UseViewDataResult<T> {
  // Type-safe loading with view type validation
  // Automatic URL construction from view type
  // Comprehensive error handling and loading states
}

export function useStationOverview() {
  return useViewData('station-overview');
}
```
- [x] Create `src/lib/hooks/useViewData.ts` *(Comprehensive implementation with TypeScript generics)*
- [x] Add view data types to `src/types/data.ts` *(StationOverviewData, ViewType)*
- [x] Implement type-safe hook with view validation
- [x] Run tests: `npm run test -- tests/unit/test_view_hooks.spec.tsx`
- [x] **ALL 9 TESTS PASS** *(Loading states, error handling, type safety, view validation)*
- [x] **MANUAL TEST CHECKPOINT**:
  - [x] Hook loads correct CDN paths: `/views/station_overview.json`
  - [x] Type inference works correctly for different view types
  - [x] Error handling for invalid view types and network failures

**âœ… SUCCESS**: Hook implementation complete with comprehensive test coverage

### **2.2 Create Parallel Station Page (/stations-v2)**

#### **Step 2.2.1: Create New Page with Tests**
```typescript
// tests/unit/test_stations_v2_page.spec.tsx
describe('Stations V2 Page', () => {
  // Comprehensive test suite with 15 tests covering:
  // - Page rendering and structure
  // - Loading states and error handling
  // - Data display with exact content verification
  // - Performance indicators and accessibility
  // - Empty state handling
});
```
- [x] Create `src/app/stations-v2/` directory
- [x] Create comprehensive test suite in `tests/unit/test_stations_v2_page.spec.tsx`
- [x] **15 TESTS WRITTEN** covering all page states and functionality
- [x] Handle Jest module resolution issues (relative paths work)
- [x] Run tests: `npm run test -- tests/unit/test_stations_v2_page.spec.tsx`
- [x] Initial tests FAILED as expected (no implementation)

**âœ… SUCCESS**: Comprehensive test suite ready with full coverage

#### **Step 2.2.2: Implement Minimal Stations-v2 Page**
```typescript
// src/app/stations-v2/page.tsx
export default function StationsV2Page() {
  const { data, loading, error } = useStationOverview();
  
  // Comprehensive implementation with:
  // - Loading states with spinner
  // - Error handling with styled error messages
  // - Full station data display (cards with stats)
  // - Coordinate display and deployment information
  // - Metadata section and responsive design
}
```
- [x] Create `src/app/stations-v2/page.tsx` with full implementation
- [x] Create `src/app/stations-v2/page.content.tsx` following content helper pattern
- [x] Implement comprehensive page with all required functionality
- [x] Run tests: `npm run test -- tests/unit/test_stations_v2_page.spec.tsx`
- [x] **ALL 15 TESTS PASS** âœ…

**âœ… SUCCESS**: Complete stations-v2 page implementation with perfect test coverage

#### **Step 2.2.3: Performance Comparison Test**
- [x] Start dev server: `npm run dev`
- [x] Open browser DevTools Network tab
- [x] Navigate to `/stations` (old version)
- [x] Record: Total data transferred: **9KB** (stations data already optimized)
- [x] Record: Load time: Fast
- [x] Navigate to `/stations-v2` (new version)  
- [x] Record: Total data transferred: **7KB** (2KB improvement)
- [x] Record: Load time: Fast
- [x] **SUCCESS CRITERIA**: New version works âœ… (bigger gains expected for species/acoustic data)

**âš ï¸ ROLLBACK TRIGGER**: If new version loads > 100KB or is slower, investigate before proceeding

### **2.3 Side-by-Side Testing Checklist**

#### **Functionality Comparison**
- [x] Old `/stations` page loads correctly
- [x] New `/stations-v2` page loads correctly
- [x] Both show same 3 stations (9M, 14M, 37M)
- [x] Station data displays correctly (new version has simplified layout as expected)
- [x] Summary statistics accurate
- [x] **MANUAL TEST**: Basic functionality verified

#### **Data Accuracy Verification**
- [x] Station count matches: 3 stations
- [x] Station names correct: 9M, 14M, 37M  
- [x] Deployment information consistent
- [x] Year ranges match data scope
- [x] Document discrepancies: **None - data accurate**

#### **Performance Metrics**
- [x] Old page initial load: **9KB** (already optimized for stations)
- [x] New page initial load: **7KB** (2KB improvement)
- [x] Improvement factor: **Modest for stations, expecting 100x+ for species/acoustic data**

**âœ… SUCCESS**: Phase 2 completed, ready for Phase 2b (species timeline implementation)**

---

## Phase 2b: Species Timeline View (High Performance Impact)

### **2b.1 Species Timeline View Generator**

#### **Step 2b.1.1: Write Tests for Species Timeline Generator**
```python
# tests/unit/test_species_views.py
def test_generate_species_timeline_structure():
    """Test that species timeline has correct structure."""
    result = generate_species_timeline(mock_data_dir)
    assert 'species_timeline' in result
    assert 'metadata' in result
    assert 'temporal_aggregation' in result

def test_species_timeline_size():
    """Test that output is reasonably sized (~100KB target)."""
    result = generate_species_timeline(mock_data_dir)
    json_str = json.dumps(result)
    # Allow up to 100KB for species timeline data
    assert len(json_str) < 100 * 1024

def test_monthly_aggregation():
    """Test monthly aggregation reduces data size significantly."""
    result = generate_species_timeline(mock_data_dir)
    # Should have monthly aggregated data, not hourly
    for species_data in result['species_timeline']:
        assert 'monthly_detections' in species_data
        assert 'detection_frequency' in species_data

def test_species_filtering():
    """Test that only biological species are included, not anthropogenic sounds."""
    result = generate_species_timeline(mock_data_dir)
    for species_data in result['species_timeline']:
        # Should only contain biological species based on det_column_names.csv
        assert species_data['category'] == 'biological'
```
- [x] Write comprehensive tests in `tests/unit/test_species_views.py`
- [x] Tests should cover: structure, size limits, monthly aggregation, species filtering
- [x] Run tests: `uv run pytest tests/unit/test_species_views.py -v` *(âœ… ALL 9 TESTS PASS)*

#### **Step 2b.1.2: Implement Species Timeline Generator**
```python
# mbon_analysis/views/species_views.py
def generate_species_timeline(processed_data_dir: Path) -> dict:
    """Generate species timeline optimized for interactive charts.
    
    Key optimizations:
    - Monthly aggregation (not hourly) to reduce data size
    - Only biological species (filter out anthropogenic sounds)
    - Detection frequency calculations
    - Temporal pattern summaries
    """
    # Implementation will aggregate detection data by month/species
    # Target: ~100KB output vs MB+ of raw detection data
```
- [x] Implement function in `mbon_analysis/views/species_views.py`
- [x] Focus on monthly aggregation to reduce data size dramatically
- [x] Filter to biological species only using species metadata
- [x] Run tests: `uv run pytest tests/unit/test_species_views.py -v` *(âœ… ALL 9 TESTS PASS)*

#### **Step 2b.1.3: Create Species Timeline Script Wrapper**
```python
# scripts/view_generation/generate_species_views.py
def main():
    data = generate_species_timeline(Path('data/cdn/processed'))
    output_path = Path('data/cdn/views/species_timeline.json')
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w') as f:
        json.dump(data, f, indent=2)
    
    print(f"âœ… Generated {output_path} ({len(json.dumps(data)) / 1024:.1f} KB)")
```
- [x] Create script wrapper following the pattern
- [x] Test script: `uv run scripts/view_generation/generate_species_views.py`
- [x] Verify output size is < 100KB *(âœ… 1.6KB - excellent performance, 5 species included)*

### **2b.2 Frontend Integration**

#### **Step 2b.2.1: Add Species Timeline Hook**
- [x] Update `useViewData.ts` to support `'species-timeline'` view type
- [x] Add type definitions for species timeline data
- [x] Create convenience hook: `useSpeciesTimeline()`

#### **Step 2b.2.2: Create Species Timeline Page**
- [x] Create `src/app/species-v2/page.tsx` with species timeline visualization
- [x] Implement comprehensive page with species cards and timeline data
- [x] Test performance: loads 1.6KB vs MB+ of raw detection data *(âœ… 1000x+ improvement)*

**âœ… SUCCESS**: Phase 2b completed - Species timeline view shows dramatic performance improvement

---

## Phase 3: CDN Automation System âœ… COMPLETED

### **3.1 Environment Configuration** âœ…
- [x] Set up `.env.local` with comprehensive CDN provider configurations
- [x] Added support for local_dev, cloudflare_r2, and aws_s3 providers
- [x] Included security guidance and credential templates
- [x] Authentication handling for both Cloudflare R2 and AWS S3

```bash
# .env.local (configured)
CDN_PROVIDER=local_dev
CDN_BASE_URL=http://localhost:3000

# Production templates ready for:
# - Cloudflare R2 with account_id, access_key, secret_key, bucket_name
# - AWS S3 with access_key, secret_key, bucket_name, region
```

### **3.2 Smart CDN Sync** âœ…
- [x] Implemented `CDNDeployer` class with hash-based change detection
- [x] Only uploads files that have changed (SHA-256 hash comparison)
- [x] Atomic deployments with comprehensive error handling
- [x] Automatic manifest generation and management
- [x] Supports multiple CDN providers (Cloudflare R2, AWS S3, local dev)
- [x] Deployment validation with HTTP accessibility testing
- [x] Detailed deployment results and progress reporting

**Implementation Complete:**
```python
# mbon_analysis/deployment/cdn_sync.py
class CDNDeployer:
    def sync_views(self, local_views_dir: Path) -> DeploymentResult:
        # âœ… Generate file hashes
        # âœ… Compare with remote manifest
        # âœ… Upload only changed files
        # âœ… Update manifest atomically  
        # âœ… Validate deployment
        # âœ… Return detailed results with performance metrics
```

### **3.3 Package.json Integration** âœ…
- [x] Added comprehensive deployment scripts to `package.json`
- [x] `npm run deploy` - Full deployment pipeline
- [x] `npm run deploy:check` - Check what would be deployed (no uploads)
- [x] `npm run deploy:dry-run` - Test deployment process without uploads
- [x] `npm run generate-views` - Generate view files only
- [x] Integration with existing workflow scripts

```json
{
  "scripts": {
    "deploy": "uv run scripts/deployment/full_deploy.py",
    "deploy:check": "uv run scripts/deployment/full_deploy.py --check-only", 
    "deploy:dry-run": "uv run scripts/deployment/full_deploy.py --dry-run",
    "generate-views": "uv run scripts/view_generation/generate_station_views.py && uv run scripts/view_generation/generate_species_views.py"
  }
}
```

### **3.4 Deployment Infrastructure** âœ…
- [x] Created `mbon_analysis/deployment/` module with:
  - [x] `cdn_sync.py` - Smart CDN synchronization with authentication
  - [x] `manifest_generator.py` - Automatic manifest creation and comparison
  - [x] `validation.py` - Deployment validation and health checks
- [x] Created `scripts/deployment/` with:
  - [x] `full_deploy.py` - Complete deployment orchestration script
  - [x] `setup_guide.md` - Comprehensive CDN setup documentation
- [x] All 7 CDN sync tests passing
- [x] Support for boto3 integration (Cloudflare R2 and AWS S3)
- [x] Proper error handling for missing credentials

### **3.5 Testing and Validation** âœ…
- [x] Successfully tested with `npm run deploy:check`
- [x] Verified 2 view files ready for deployment:
  - `species_timeline.json` (2.4 KB)
  - `station_overview.json` (4.5 KB)
- [x] Hash-based change detection working correctly
- [x] Local development mode properly configured
- [x] All deployment validation systems operational

### **3.6 Live CDN Deployment** âœ…
- [x] **REAL DEPLOYMENT SUCCESS**: `npm run deploy:dry-run` with live Cloudflare R2
- [x] Authentication working with actual credentials
- [x] Files successfully deployed to: `https://pub-71436b8d94864ba1ace2ef29fa28f0f1.r2.dev/views/`
- [x] Clean separation: new `/views/` path, existing `/processed/` untouched
- [x] Environment variable loading fixed with python-dotenv integration
- [x] boto3 integration working for Cloudflare R2 API access
- [x] Deployment shows: "CDN Sync (cloudflare_r2): 3 files processed, 3 uploaded, 0 skipped, 7.8 KB"

### **3.7 Data Sync System Coexistence** âœ…  
- [x] Existing `data_manifest.json` and data sync system preserved
- [x] New `views/manifest.json` operates independently  
- [x] Zero conflicts between old and new manifest systems
- [x] Data sync continues supporting ongoing acoustic index updates
- [x] Clean migration path: both systems can coexist indefinitely

**âœ… SUCCESS**: Phase 3 CDN Automation System fully implemented, tested, AND deployed to production CDN
```

---

## Phase 4: Full Migration

### **4.1 Acoustic Summary View âœ… COMPLETED**

**ðŸŽ¯ MAJOR SUCCESS**: Achieved **8,686x performance improvement** - reduced 166MB `acoustic_indices.json` to 19.6KB `acoustic_summary.json` while preserving all research value through PCA analysis.

#### **âœ… Completed Implementation**
- [x] **Test-Driven Development**: Created comprehensive test suite with 10 tests covering acoustic summary generation
- [x] **PCA Analysis**: Implemented scikit-learn-based PCA reducing 61 acoustic indices to 5 principal components  
- [x] **Index Categorization**: Organized indices into 6 research domains (temporal, frequency, complexity, diversity, bioacoustic, spectral)
- [x] **Performance Optimization**: 34,700 acoustic measurements processed into compact summary format
- [x] **Script Integration**: Added `generate_acoustic_views.py` following established deployment pattern
- [x] **Frontend Implementation**: Created `src/app/acoustic-v2/page.tsx` with comprehensive PCA visualization
- [x] **Type Safety**: Extended TypeScript definitions with `AcousticSummaryData` interface
- [x] **Hook Integration**: Added `useAcousticSummary()` convenience hook with view data loading
- [x] **CDN Deployment**: Successfully deployed to production CDN with custom domain (https://waveformdata.work)
- [x] **CORS & CSP Configuration**: Resolved Content Security Policy and CORS issues for production deployment
- [x] **Performance Metrics**: Displays 8,686x improvement indicator on frontend page

#### **âœ… Technical Achievements**
- **Data Processing**: Loads 61 acoustic indices with 34,700 measurements
- **Dimensionality Reduction**: PCA components explain variance across acoustic environment
- **Research Integration**: 6 index categories align with marine acoustics research domains
- **Production Ready**: Full CDN integration with change detection and atomic deployments
- **Developer Experience**: Complete TDD workflow with manual testing checkpoints

#### **âœ… Live Production Status**
- **CDN URL**: https://waveformdata.work/views/acoustic_summary.json (19.6KB)
- **Page URL**: /acoustic-v2 (fully functional with PCA visualization)
- **Performance**: 8,686x faster loading compared to raw acoustic indices
- **Data Integrity**: All 61 indices preserved in categorized format with PCA loadings

### **4.2 Incremental Component Migration Strategy ðŸŽ¯ CURRENT FOCUS**

**NEW APPROACH**: Instead of creating -v2 pages, we'll generate optimized views for existing components and gradually swap data sources in-place. This provides cleaner migration and immediate benefits.

#### **Migration Workflow**
1. **Generate View** â†’ 2. **Test with Component** â†’ 3. **Update Hook** â†’ 4. **Swap Data Source**

#### **Chart Components & Required Views**

##### **4.2.1 RawDataLandscape Component âœ… VIEW COMPLETE, TESTING NEXT**

**View Generation Complete:**
- [x] **Tests Written**: 10 comprehensive tests in `test_chart_views.py`
- [x] **View Generator**: `generate_raw_data_landscape()` in `mbon_analysis/views/chart_views.py`
- [x] **Script Wrapper**: `scripts/view_generation/generate_chart_views.py`
- [x] **npm Integration**: Added to `npm run generate-views`
- [x] **Performance**: 32.3KB output (from 166MB+ source)
- [x] **CDN Deployed**: Successfully deployed to production (55.5KB)
- [x] **Data Coverage**: 62 indices across 4 datasets (9M/14M, FullBW/8kHz)

**Next Step: Component Integration Testing**
- [ ] **Load existing component**: `src/components/charts/RawDataLandscape.tsx`
- [ ] **Test with new data**: Update to use `raw_data_landscape.json` instead of `step1a_raw_data_landscape.json`
- [ ] **Verify functionality**: Ensure chart renders correctly with new data structure
- [ ] **Update hook**: Modify `useRawDataLandscape()` to load from views endpoint
- [ ] **Performance check**: Confirm 32KB vs previous larger file size

##### **4.2.2 IndexDistributions View ðŸŽ¯ NEXT STEP**

**Purpose**: Generate histogram distribution data for all acoustic indices to visualize their statistical properties.

**TDD Implementation Steps:**

1. **Write Tests First** (`tests/unit/test_chart_views.py`):
```python
def test_index_distributions_structure():
    """Test distributions view structure."""
    result = generate_index_distributions(mock_data_dir)
    assert 'distributions' in result
    assert 'bin_edges' in result  
    assert 'statistics' in result

def test_distribution_size_limit():
    """Test output is under 40KB."""
    result = generate_index_distributions(mock_data_dir)
    assert len(json.dumps(result)) < 40 * 1024

def test_distribution_bins():
    """Test each index has proper histogram bins."""
    result = generate_index_distributions(mock_data_dir)
    for index_name, dist in result['distributions'].items():
        assert 'counts' in dist
        assert 'bin_edges' in dist
        assert len(dist['counts']) == len(dist['bin_edges']) - 1
```

2. **Implement Generator** (`mbon_analysis/views/chart_views.py`):
   - Add `generate_index_distributions()` function
   - Calculate histogram bins for each index
   - Include summary statistics (mean, std, quartiles)

3. **Update Script Wrapper** (`scripts/view_generation/generate_chart_views.py`):
   - Add index distributions generation
   - Output to `data/cdn/views/index_distributions.json`

4. **Test & Deploy**:
   - Run tests: `uv run pytest tests/unit/test_chart_views.py -v`
   - Generate view: `npm run generate-views`
   - Deploy: `npm run deploy`

**Target**: ~40KB with histogram data for all 62 indices

##### **4.2.3 AcousticIndicesHeatmap View**
```python
def test_acoustic_heatmap_data():
    """Test heatmap data structure."""
    result = generate_acoustic_heatmap(mock_data_dir)
    assert 'temporal_matrix' in result
    assert 'indices' in result
    assert 'time_bins' in result
```

**Target**: ~60KB with hourly/daily aggregated data

##### **4.2.4 BandwidthComparison View**
```python
def test_bandwidth_comparison_data():
    """Test bandwidth comparison structure."""
    result = generate_bandwidth_comparison(mock_data_dir)
    assert 'fullBW' in result
    assert '8kHz' in result
    assert 'comparison_stats' in result
```

**Target**: ~30KB with statistical summaries

### **4.3 Migration Order (Updated)**

1. âœ… **Acoustic Summary** - **COMPLETED** with major performance breakthrough (8,686x improvement)
2. âœ… **Station Overview** - **COMPLETED** 
3. âœ… **Species Timeline** - **COMPLETED**
4. ðŸŽ¯ **Chart Views** - **IN PROGRESS** (for feature parity)
5. ðŸ“‹ **Environmental Trends** - Temperature/depth patterns
6. ðŸ“‹ **Biodiversity Patterns** - Complex co-occurrence data

### **4.4 Each Migration Step**

1. **Generate view data** using `mbon_analysis/views/`
2. **Build new page version** at `/{page}-v2`
3. **Test thoroughly** - functionality, performance, data accuracy
4. **Replace original page** once validated
5. **Clean up old version**

### **4.3 Frontend Hook Migration**

**Before:**
```typescript
const { detections, loading } = useTimelineData(); // Loads 14MB
```

**After:**  
```typescript
const { timeline, loading } = useSpeciesTimeline(); // Loads 100KB
```

---

## Phase 5: Clean Up

### **5.1 Remove Old System**

- Delete paginated files and pagination logic
- Remove large monolithic JSON files
- Clean up unused scripts and hooks
- Update documentation

### **5.2 Clean Up Mixed Processed/View Files**

**âš ï¸ IMPORTANT**: The current `data/cdn/processed/` directory contains a mix of true processed data and view files. This needs to be cleaned up:

**True Processed Data (keep in processed/)**:
- `detections.json` - Raw detection records from Excel
- `environmental.json` - Raw temperature/depth measurements from Excel
- `acoustic_indices.json` - Raw acoustic index calculations from CSV
- `deployment_metadata.json` - Deployment information from Excel
- `stations.json` - Station definitions
- `species.json` - Species metadata

**View Files (move to views/ or delete if replaced)**:
- `monthly_detections.json` â†’ Move to `views/` or replace with new view generator
- `pca_biplot*.json` â†’ Move to `views/` as acoustic analysis views
- `step1a_raw_data_landscape.json` â†’ Move to `views/` or `analysis/` folder
- `step1b_index_distributions.json` â†’ Move to `views/` or `analysis/` folder
- `paginated/` folder â†’ **DELETE** (replaced by view-based system)
- `*_summary.json` files â†’ **DELETE** (replaced by view-based system)
- `acoustic_indices_detailed.json`, `acoustic_indices_raw.json` â†’ Evaluate if needed

**Clean Architecture Goal**:
```
data/cdn/
â”œâ”€â”€ processed/     # â† Only normalized data from Excel/CSV
â”‚   â”œâ”€â”€ detections.json
â”‚   â”œâ”€â”€ environmental.json
â”‚   â”œâ”€â”€ acoustic_indices.json
â”‚   â”œâ”€â”€ deployment_metadata.json
â”‚   â”œâ”€â”€ stations.json
â”‚   â””â”€â”€ species.json
â””â”€â”€ views/         # â† Only optimized frontend views
    â”œâ”€â”€ station_overview.json
    â”œâ”€â”€ species_timeline.json
    â”œâ”€â”€ acoustic_summary.json
    â”œâ”€â”€ environmental_trends.json
    â””â”€â”€ biodiversity_patterns.json
```

### **5.3 Final Package.json**

```json
{
  "scripts": {
    "process-data": "uv run scripts/dashboard_prep/generate_views.py",
    "deploy": "npm run process-data && uv run scripts/deployment/full_deploy.py",
    "deploy:check": "uv run scripts/deployment/full_deploy.py --check-only",
    "dev": "next dev",
    "dev:fresh": "npm run process-data && next dev"
  }
}
```

**Single command deployment:**
```bash
npm run deploy
# âœ… Processes Excel files
# âœ… Generates optimized view files  
# âœ… Uploads only changed files to CDN
# âœ… Updates manifest automatically
# âœ… Validates deployment
# âœ… Reports results
```

---

## Deployment and Rollback Procedures

### **Safe Deployment Checklist**

#### **Pre-Deployment Verification**
- [ ] All automated tests passing: `uv run pytest && npm test`
- [ ] Manual testing completed for current phase
- [ ] Performance metrics documented
- [ ] Data accuracy verified
- [ ] No console errors in browser
- [ ] Memory usage acceptable (check DevTools)

#### **Deployment Steps**
1. **Generate Views Locally**
   - [ ] Run: `uv run scripts/view_generation/generate_station_views.py`
   - [ ] Verify output size: `ls -lh data/cdn/views/`
   - [ ] Quick data check: `head -20 data/cdn/views/station_overview.json`

2. **Test Locally with Production Build**
   - [ ] Build: `npm run build`
   - [ ] Start: `npm start`
   - [ ] Test `/stations-v2` with production build
   - [ ] Verify performance still good

3. **Upload to CDN (Manual for now)**
   - [ ] Upload `data/cdn/views/` folder to CDN
   - [ ] Verify files accessible via CDN URL
   - [ ] Test with live CDN data

4. **Monitor After Deployment**
   - [ ] Check browser console for errors
   - [ ] Monitor network tab for failed requests
   - [ ] Verify all features working
   - [ ] Document any issues: _____________

### **Rollback Procedures**

#### **Immediate Rollback Triggers**
If ANY of these occur, rollback immediately:
- [ ] Page crashes or shows errors
- [ ] Data is incorrect or missing
- [ ] Performance degradation (slower than old version)
- [ ] Features stop working
- [ ] User reports issues

#### **How to Rollback**

**Option 1: Keep Old Page Active (Recommended)**
```typescript
// Don't replace /stations yet, keep both:
// /stations (old, working)
// /stations-v2 (new, testing)
```
- Simply direct users back to `/stations` if issues found

**Option 2: Quick Code Revert**
```bash
# If you already replaced the original page
git stash  # Save current work
git checkout HEAD -- src/app/stations/page.tsx
npm run dev  # Verify old version works
```

**Option 3: CDN Rollback**
```bash
# Keep backup of old views
data/cdn/views_backup/  # Previous version
data/cdn/views/         # Current version

# To rollback: re-upload views_backup to CDN
```

#### **Post-Rollback Actions**
- [ ] Document what went wrong
- [ ] Write failing test case for the issue
- [ ] Fix issue in development
- [ ] Add additional tests
- [ ] Try deployment again

---

## Success Metrics

### **Performance Improvements**
- **Initial Load**: 218MB â†’ <500KB (400x faster)
- **File Count**: 61 files â†’ 5-10 files  
- **CDN Management**: Manual â†’ Fully automated
- **Deployment Time**: Manual minutes â†’ Automated seconds

### **Developer Experience**
- **One command deploy**: `npm run deploy`
- **Safe migration**: No risk to existing system during transition
- **Clean codebase**: All logic in package, scripts are thin wrappers
- **Easy maintenance**: Clear separation of concerns

### **Risk Mitigation**
- **Parallel systems**: Old and new work simultaneously during migration
- **Incremental migration**: One page at a time
- **Automated testing**: Deployment validation built-in
- **Easy rollback**: Previous versions always available

---

## Open Questions

1. âœ… **Which page should we migrate first?** Station overview confirmed as safest starting point.

2. âœ… **CDN provider preferences?** Cloudflare R2 confirmed - cost effective and reliable.

3. **Manifest format?** JSON with file hashes and metadata for change detection.

4. **Validation strategy?** Automated tests for data accuracy and deployment health checks.

5. **Rollback mechanism?** Keep N previous versions on CDN for safe rollbacks.

---

## Next Steps

1. **Review this plan** - Does the approach feel right?

2. **Environment setup** - CDN credentials and configuration

3. **Start with station overview** - Build first view generator

4. **Test automation** - Ensure CDN sync works reliably  

5. **Incremental migration** - One page at a time, low risk

This approach gives you the clean, automated, maintainable system you want while minimizing risk during the transition.
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        var scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          var element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          var hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          var newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((entries) => {
          setHeight();
        });
        resizeObserver.observe(obj.contentWindow.document.body);
      }
    </script>
    <marimo-filename hidden>10_view_generation.py</marimo-filename>
    <!-- TODO(Trevor): Legacy, required by VS Code plugin. Remove when plugin is updated (see marimo/server/_templates/template.py) -->
    <marimo-version data-version="{{ version }}" hidden></marimo-version>
    <marimo-user-config data-config="{{ user_config }}" hidden></marimo-user-config>
    <marimo-server-token data-token="{{ server_token }}" hidden></marimo-server-token>
    <!-- /TODO -->
    <title>10 view generation</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/index-DKEudB02.js"></script>
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.16.0/dist/assets/index-Cx0bsY1w.css">
  
<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <!-- This is a portal for the data editor to render in -->
    <div id="portal" data-testid="glide-portal" style="position: fixed; left: 0; top: 0; z-index: 9999"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "10_view_generation.py",
            "mode": "read",
            "version": "0.16.0",
            "serverToken": "static",
            "config": {"ai": {"models": {"custom_models": [], "displayed_models": []}}, "completion": {"activate_on_typing": true, "copilot": false}, "display": {"cell_output": "above", "code_editor_font_size": 14, "dataframes": "rich", "default_table_max_columns": 50, "default_table_page_size": 10, "default_width": "medium", "reference_highlighting": false, "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": true}}, "package_management": {"manager": "pip"}, "runtime": {"auto_instantiate": true, "auto_reload": "off", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import marimo as mo", "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n# Notebook 10: View Generation\n\n**Purpose**: Generate data \"views\" for online plots and interactive figures.  \n**Key Outputs**: Data views in json format\n\nTo avoid doing extensive processing, filtering and loading of large files on the client/browser side, we will generate specific data files for each figure. Each view will contain ONLY the data needed for that particular plot, already formatted in the way it's needed.\n\n# Test comment to trigger automatic HTML export\n\"\"\"\n)", "code_hash": "6d47757e60cf4d43ea3de1658688b0f4", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "MJUe", "name": "_"}, {"code": "import pandas as pd\nimport numpy as np\nimport os\nfrom pathlib import Path\n\nfrom scipy.cluster.hierarchy import linkage, dendrogram\nfrom scipy.spatial.distance import squareform\n\n# Find project root by looking for the data folder\ncurrent_dir = Path(__file__).parent if \"__file__\" in locals() else Path.cwd()\nproject_root = current_dir\nwhile not (project_root / \"data\").exists() and project_root != project_root.parent:\n    project_root = project_root.parent\n\nDATA_ROOT = project_root / \"data\"\nVIEWS_FOLDER = str(DATA_ROOT / \"views\") + \"/\"", "code_hash": "f2c55a07d078d77f519f84a12448bdb1", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n## Station map\n\nThe site has a Mapbox station map and requires the station coordinates. These can be extracted from a parquet formatted metadata file located in the data/processed/metadata folder.\n\"\"\"\n)", "code_hash": "868b0e55a3767369591bc92c60a1866c", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "bkHC", "name": "_"}, {"code": "# Import the parquet file as a dataframe using Pandas\nstation_metadata_df = pd.read_parquet(DATA_ROOT / \"processed/metadata/deployments.parquet\")\n\n# Extract a subset of rows where the \"Station\" column has all unique values\nunique_stations_df = station_metadata_df.drop_duplicates(subset='Station')\n\n# List of stations used in this study\ncurrent_study = [\"9M\", \"14M\", \"37M\"]\n\n# Aggregate data to get total deployments, average depth (m) and average hydrophone depth (m) per station\naggregated_data = station_metadata_df.groupby('Station').agg(\n    total_deployments=pd.NamedAgg(column='Deployment number', aggfunc='count'),\n    avg_depth_m=pd.NamedAgg(column='Depth (m)', aggfunc='mean'),\n    avg_hydrophone_depth_m=pd.NamedAgg(column='Hydrophone Depth (m)', aggfunc='mean')\n).reset_index()\n\n# Round the averages to one decimal place\naggregated_data['avg_depth_m'] = aggregated_data['avg_depth_m'].round(1)\naggregated_data['avg_hydrophone_depth_m'] = aggregated_data['avg_hydrophone_depth_m'].round(1)\n\n# Merge aggregated data with the simplified dataframe\nstations_locations = pd.merge(unique_stations_df[[\"Station\", \"GPS Lat\", \"GPS Long\"]], aggregated_data, on=\"Station\")\n\n# Add a new column for the current study\nstations_locations.loc[:, 'current_study'] = stations_locations['Station'].isin(current_study)\n\n# Save the dataframe to a JSON file in the views folder\nstations_locations.to_json(f\"{VIEWS_FOLDER}stations_locations.json\", orient='records')", "code_hash": "0e321fbc3100030e984da1a00ecd4b26", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n## Heatmaps\n\nThese views will include acoustic indices, manual detections, RMS SPL, and environmental data.\n\"\"\"\n)", "code_hash": "25a586965c4b8639003cd851feab3cf4", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "PKri", "name": "_"}, {"code": "## Manual detections\n# Import manual detections data\ndetections_aligned_df = pd.read_parquet(DATA_ROOT / \"processed/02_detections_aligned_2021.parquet\")\n# save to json\ndetections_aligned_df.to_json(f\"{VIEWS_FOLDER}02_detections_aligned_2021.json\", orient=\"records\")\n\n\n## Acoustic indices\n# Import acoustic index data\nindices_aligned_reduced_df = pd.read_parquet(DATA_ROOT / \"processed/03_reduced_acoustic_indices.parquet\")\n\n# Add hour field for heatmap visualization (extract hour from datetime)\n# indices_aligned_reduced_df['datetime'] = pd.to_datetime(indices_aligned_reduced_df['datetime'])\n# indices_aligned_reduced_df['hour'] = indices_aligned_reduced_df['datetime'].dt.hour\n\n# Save to JSON\nindices_aligned_reduced_df.to_json(f\"{VIEWS_FOLDER}03_reduced_acoustic_indices.json\", orient=\"records\")\n\n\n## RMS SPL + environmental data\n# Import env data\nenvironment_aligned_df = pd.read_parquet(DATA_ROOT / \"processed/02_environmental_aligned_2021.parquet\")\n# save to json\nenvironment_aligned_df.to_json(f\"{VIEWS_FOLDER}02_environmental_aligned_2021.json\", orient=\"records\")", "code_hash": "5b839c9eb26141334d209e92caa86089", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n## Full Acoustic Indices for Enhanced Heatmap\n\n**Purpose**: Export the complete dataset with all acoustic indices and cluster metadata for the enhanced heatmap visualization.\n\n**Data Files**:\n- **Full indices dataset**: All 61 acoustic indices aligned to 2-hour resolution\n- **Cluster metadata**: Cluster assignments and selection status for each index\n\nThis allows users to explore all indices organized by functional clusters in the heatmap.\n\"\"\"\n)", "code_hash": "9bb3b9bd66fe159b95d7a199b536282e", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "SFPL", "name": "_"}, {"code": "## Full Acoustic Indices Dataset\ntry:\n    # Load the complete dataset with all indices\n    indices_full_df = pd.read_parquet(DATA_ROOT / \"processed/02_acoustic_indices_aligned_2021_full.parquet\")\n\n    # Add hour field for heatmap visualization (extract hour from datetime)\n    # indices_full_df['datetime'] = pd.to_datetime(indices_full_df['datetime'])\n    # indices_full_df['hour'] = indices_full_df['datetime'].dt.hour\n\n    # Save full indices data\n    indices_full_df.to_json(f\"{VIEWS_FOLDER}acoustic_indices_full.json\", orient=\"records\")\n\n    print(f\"Saved full indices dataset:\")\n    print(f\"  Shape: {indices_full_df.shape}\")\n    print(f\"  Stations: {indices_full_df['station'].unique() if 'station' in indices_full_df.columns else 'N/A'}\")\n\n    # Count indices (excluding datetime, station, year columns)\n    index_cols = [col for col in indices_full_df.columns if col not in ['datetime', 'station', 'year']]\n    print(f\"  Total indices: {len(index_cols)}\")\nexcept FileNotFoundError:\n    print(\"Full indices dataset not found - run notebook 3 first to generate it\")\n    indices_full_df = pd.DataFrame()\n\n## Cluster Metadata\ntry:\n    # Load cluster metadata\n    cluster_metadata_df_heatmap = pd.read_parquet(DATA_ROOT / \"processed/metadata/acoustic_indices_clusters.parquet\")\n\n    # Save cluster metadata\n    cluster_metadata_df_heatmap.to_json(f\"{VIEWS_FOLDER}acoustic_indices_clusters.json\", orient=\"records\")\n\n    print(f\"\\nSaved cluster metadata:\")\n    print(f\"  Total indices: {len(cluster_metadata_df_heatmap)}\")\n    print(f\"  Clusters: {cluster_metadata_df_heatmap['cluster_id'].nunique() if 'cluster_id' in cluster_metadata_df_heatmap.columns else 'N/A'}\")\n    print(f\"  Selected indices: {cluster_metadata_df_heatmap['is_selected'].sum() if 'is_selected' in cluster_metadata_df_heatmap.columns else 'N/A'}\")\nexcept FileNotFoundError:\n    print(\"Cluster metadata not found - run notebook 3 first to generate it\")\n    cluster_metadata_df_heatmap = pd.DataFrame()", "code_hash": "5b5cb3d43863eabf9340f192be3f767d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n## Acoustic indices explainer cards\n\n**Purpose**: Create histogram data for interactive cards visualization showing distribution of each acoustic index by station.\n\n**Data Structure**: For each index-station combination, we generate:\n- Histogram bins with counts and frequencies\n- Summary statistics (min, max, mean, std)\n- Metadata (category, subcategory, description) for card flip descriptions\n- Station filtering capability for dropdown interaction\n\n**Output**: JSON file optimized for D3.js histogram plotting with flip card metadata\n\"\"\"\n)", "code_hash": "2ead1f2589537294e31cc02a7396bad0", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "RGSE", "name": "_"}, {"code": "## Acoustic Indices Metadata\n# Import indices metadata\nacoustic_indices_metadata_df = pd.read_parquet(DATA_ROOT / \"processed/metadata/acoustic_indices.parquet\")\n# save to json\nacoustic_indices_metadata_df.to_json(f\"{VIEWS_FOLDER}acoustic_indices.json\", orient=\"records\")\n\n## Load Cluster Metadata\ntry:\n    cluster_metadata_df = pd.read_parquet(DATA_ROOT / \"processed/metadata/acoustic_indices_clusters.parquet\")\n    print(f\"Loaded cluster metadata for {len(cluster_metadata_df)} indices\")\nexcept FileNotFoundError:\n    print(\"Warning: Cluster metadata not found - histograms will be generated without cluster information\")\n    cluster_metadata_df = pd.DataFrame()\n\n## Acoustic Indices Cards Data Preparation\n# Get the list of acoustic index columns (exclude datetime, station, year)\nindex_columns = [col for col in indices_full_df.columns\n                if col not in ['datetime', 'station', 'year']]\n\nprint(f\"Preparing histogram data for {len(index_columns)} indices...\")\n\n# Create histogram data for each index and station\nindices_histogram_data = []\n\n# Number of bins for histograms\nn_bins = 30\n\nfor station in indices_full_df['station'].unique():\n    station_data = indices_full_df[indices_full_df['station'] == station]\n\n    for index_name in index_columns:\n        # Get values for this index and station\n        values = station_data[index_name].dropna()\n\n        if len(values) > 0:\n            # Create histogram\n            hist, bin_edges = pd.cut(values, bins=n_bins, retbins=True, include_lowest=True)\n            hist_counts = hist.value_counts().sort_index()\n\n            # Create bin centers for plotting\n            bin_centers = [(bin_edges[i] + bin_edges[i+1]) / 2 for i in range(len(bin_edges)-1)]\n\n            # Get metadata for this index\n            metadata_row = acoustic_indices_metadata_df[acoustic_indices_metadata_df['Prefix'] == index_name]\n\n            if len(metadata_row) > 0:\n                category = metadata_row.iloc[0]['Category']\n                subcategory = metadata_row.iloc[0]['Subcategory']\n                description = metadata_row.iloc[0]['Description']\n            else:\n                category = \"Unknown\"\n                subcategory = \"Unknown\"\n                description = f\"No description available for {index_name}\"\n\n            # Get cluster information for this index\n            cluster_info = cluster_metadata_df[cluster_metadata_df['index_name'] == index_name]\n            if len(cluster_info) > 0:\n                cluster_id = int(cluster_info.iloc[0]['cluster_id'])\n                cluster_size = int(cluster_info.iloc[0]['cluster_size'])\n                is_selected = bool(cluster_info.iloc[0]['is_selected'])\n                selection_rationale = cluster_info.iloc[0]['selection_rationale']\n            else:\n                cluster_id = None\n                cluster_size = None\n                is_selected = None\n                selection_rationale = None\n\n            # Create histogram data structure\n            histogram_data = []\n            for i, (interval, count) in enumerate(hist_counts.items()):\n                histogram_data.append({\n                    'bin_center': bin_centers[i],\n                    'bin_start': interval.left,\n                    'bin_end': interval.right,\n                    'count': int(count),\n                    'frequency': count / len(values)  # normalized frequency\n                })\n\n            # Add entry for this index-station combination\n            index_data = {\n                'index_name': index_name,\n                'station': station,\n                'category': category,\n                'subcategory': subcategory,\n                'description': description,\n                'total_samples': len(values),\n                'min_value': float(values.min()),\n                'max_value': float(values.max()),\n                'mean_value': float(values.mean()),\n                'std_value': float(values.std()),\n                'histogram': histogram_data\n            }\n\n            # Add cluster information if available\n            if cluster_id is not None:\n                index_data.update({\n                    'cluster_id': cluster_id,\n                    'cluster_size': cluster_size,\n                    'is_selected': is_selected,\n                    'selection_rationale': selection_rationale\n                })\n\n            indices_histogram_data.append(index_data)\n\nprint(f\"Generated {len(indices_histogram_data)} histogram datasets\")\n\n# Save to JSON\nimport json\nwith open(f\"{VIEWS_FOLDER}acoustic_indices_histograms.json\", 'w') as f:\n    json.dump(indices_histogram_data, f, indent=2)", "code_hash": "0753a43ed760a842ccedc6d545878fa7", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n## Correlation Heatmap Data\n\n**Purpose**: Generate correlation matrix and dendrogram data for the index reduction visualization.\n\n**Data Structure**: Pre-computed correlation values, dendrogram layout, and cluster metadata optimized for D3.js rendering with sticky labels and aligned dendrogram.\n\"\"\"\n)", "code_hash": "43fe4abcf0e2bb8319a7bcc69d1512a6", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "emfo", "name": "_"}, {"code": "\n## Prepare correlation heatmap data\ntry:\n    # Load cluster metadata for ordering and colors\n    heatmap_cluster_metadata = pd.read_parquet(DATA_ROOT / \"processed/metadata/acoustic_indices_clusters.parquet\")\n    print(f\"Loaded cluster metadata for {len(heatmap_cluster_metadata)} indices\")\n\n    # Get acoustic index columns (exclude datetime, station, year)\n    index_columns_heatmap = [col for col in indices_full_df.columns\n                    if col not in ['datetime', 'station', 'year']]\n\n    print(f\"Computing correlation matrix for {len(index_columns_heatmap)} acoustic indices...\")\n\n    # Compute correlation matrix\n    correlation_matrix = indices_full_df[index_columns_heatmap].corr()\n\n    # Order indices by cluster for visual grouping\n    # First, create a mapping of index to cluster\n    heatmap_index_to_cluster = dict(zip(heatmap_cluster_metadata['index_name'],\n                                       heatmap_cluster_metadata['cluster_id']))\n\n    # Sort indices by cluster_id, then by name within cluster\n    heatmap_ordered_indices = sorted(index_columns_heatmap,\n                                   key=lambda x: (heatmap_index_to_cluster.get(x, 999), x))\n\n    # Reorder correlation matrix\n    heatmap_correlation_matrix = correlation_matrix.loc[heatmap_ordered_indices, heatmap_ordered_indices]\n\n    ## Generate hierarchical clustering dendrogram\n    # Convert correlation to distance (1 - |correlation|)\n    # Use absolute correlation to ensure positive distances\n    heatmap_distance_matrix = 1 - heatmap_correlation_matrix.abs()\n\n    # Ensure all distances are non-negative and handle any floating point errors\n    heatmap_distance_matrix = heatmap_distance_matrix.clip(lower=0)\n\n    # Perform hierarchical clustering\n    heatmap_linkage_matrix = linkage(squareform(heatmap_distance_matrix), method='average')\n\n    # Generate dendrogram data (but don't plot)\n    heatmap_dendrogram_data = dendrogram(heatmap_linkage_matrix, labels=heatmap_ordered_indices, no_plot=True)\n\n    ## Flatten correlation matrix for client efficiency\n    heatmap_matrix_data = []\n    for i_heatmap, row_index in enumerate(heatmap_ordered_indices):\n        for j, col_index in enumerate(heatmap_ordered_indices):\n            correlation_value = heatmap_correlation_matrix.iloc[i_heatmap, j]\n\n            # Get cluster info\n            row_cluster = heatmap_index_to_cluster.get(row_index)\n            col_cluster = heatmap_index_to_cluster.get(col_index)\n\n            heatmap_matrix_data.append({\n                'row_index': row_index,\n                'col_index': col_index,\n                'correlation': float(correlation_value) if not pd.isna(correlation_value) else 0.0,\n                'row_cluster': int(row_cluster) if row_cluster is not None else None,\n                'col_cluster': int(col_cluster) if col_cluster is not None else None,\n                'row_position': i_heatmap,\n                'col_position': j\n            })\n\n    ## Generate index metadata with display order\n    heatmap_index_metadata = []\n    heatmap_cluster_colors = {\n        1: '#FF6B6B', 2: '#4ECDC4', 3: '#45B7D1', 4: '#96CEB4', 5: '#FFEAA7',\n        6: '#DDA0DD', 7: '#98D8C8', 8: '#F7DC6F', 9: '#BB8FCE', 10: '#85C1E9',\n        11: '#F8C471', 12: '#82E0AA', 13: '#F1948A', 14: '#85C1E9', 15: '#D2B4DE',\n        16: '#A3E4D7', 17: '#F9E79F', 18: '#FADBD8'\n    }\n\n    for i_heatmap, index_name_heatmap in enumerate(heatmap_ordered_indices):\n        heatmap_cluster_info = heatmap_cluster_metadata[heatmap_cluster_metadata['index_name'] == index_name_heatmap]\n\n        if len(heatmap_cluster_info) > 0:\n            heatmap_cluster_id = int(heatmap_cluster_info.iloc[0]['cluster_id'])\n            heatmap_is_selected = bool(heatmap_cluster_info.iloc[0]['is_selected'])\n        else:\n            heatmap_cluster_id = None\n            heatmap_is_selected = False\n\n        heatmap_index_metadata.append({\n            'index_name': index_name_heatmap,\n            'cluster_id': heatmap_cluster_id,\n            'is_selected': heatmap_is_selected,\n            'display_order': i_heatmap,\n            'cluster_color': heatmap_cluster_colors.get(heatmap_cluster_id, '#CCCCCC') if heatmap_cluster_id else '#CCCCCC'\n        })\n\n    ## Generate cluster boundary data for visual grouping\n    heatmap_clusters = []\n    heatmap_current_cluster = None\n    heatmap_start_pos = 0\n\n    for i_heatmap, metadata in enumerate(heatmap_index_metadata):\n        if metadata['cluster_id'] != heatmap_current_cluster:\n            if heatmap_current_cluster is not None:\n                # Close previous cluster\n                heatmap_clusters.append({\n                    'cluster_id': heatmap_current_cluster,\n                    'start_position': heatmap_start_pos,\n                    'end_position': i_heatmap - 1,\n                    'color': heatmap_cluster_colors.get(heatmap_current_cluster, '#CCCCCC'),\n                    'size': i_heatmap - heatmap_start_pos\n                })\n\n            # Start new cluster\n            heatmap_current_cluster = metadata['cluster_id']\n            heatmap_start_pos = i_heatmap\n\n    # Don't forget the last cluster\n    if heatmap_current_cluster is not None:\n        heatmap_clusters.append({\n            'cluster_id': heatmap_current_cluster,\n            'start_position': heatmap_start_pos,\n            'end_position': len(heatmap_index_metadata) - 1,\n            'color': heatmap_cluster_colors.get(heatmap_current_cluster, '#CCCCCC'),\n            'size': len(heatmap_index_metadata) - heatmap_start_pos\n        })\n\n    ## Prepare final data structure\n    heatmap_data = {\n        'matrix_data': heatmap_matrix_data,\n        'index_metadata': heatmap_index_metadata,\n        'dendrogram': {\n            'icoord': heatmap_dendrogram_data['icoord'],\n            'dcoord': heatmap_dendrogram_data['dcoord'],\n            'ivl': heatmap_dendrogram_data['ivl'],\n            'leaves': heatmap_dendrogram_data['leaves']\n        },\n        'clusters': heatmap_clusters,\n        'dimensions': {\n            'n_indices': len(heatmap_ordered_indices),\n            'n_clusters': len(heatmap_clusters)\n        }\n    }\n\n    # Save to JSON\n    with open(f\"{VIEWS_FOLDER}correlation_heatmap.json\", 'w') as file:\n        json.dump(heatmap_data, file, indent=2)\n\n    print(f\"Generated correlation heatmap data:\")\n    print(f\"  Matrix entries: {len(heatmap_matrix_data):,}\")\n    print(f\"  Indices: {len(heatmap_index_metadata)}\")\n    print(f\"  Clusters: {len(heatmap_clusters)}\")\n    print(f\"  Saved to: correlation_heatmap.json\")\n\nexcept Exception as e:\n    print(f\"Error generating correlation heatmap data: {e}\")", "code_hash": "1a6a6d2c6eb44eed8f3ed80a9bac4495", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hstk", "name": "_"}, {"code": "# Generate seasonal diel pattern view from notebook 4 output\ntry:\n    print(\"\\n=== GENERATING SEASONAL DIEL PATTERN VIEW ===\")\n\n    # Load the seasonal diel patterns data from notebook 4\n    diel_patterns_path = DATA_ROOT / \"processed\" / \"04_seasonal_diel_patterns.parquet\"\n\n    if not diel_patterns_path.exists():\n        print(f\"Warning: Seasonal diel patterns file not found at {diel_patterns_path}\")\n        print(\"Please run notebook 04_fish_and_indices_patterns.py first\")\n    else:\n        df_diel = pd.read_parquet(diel_patterns_path)\n\n        # Convert to JSON-friendly format\n        diel_data = {\n            'patterns': df_diel.to_dict('records'),\n            'metadata': {\n                'seasons': df_diel['season'].unique().tolist(),\n                'hours': sorted(df_diel['hour'].unique().tolist()),\n                'variables': {\n                    'acoustic_indices': df_diel[df_diel['variable_type'] == 'acoustic_index']['variable'].unique().tolist(),\n                    'manual_detections': df_diel[df_diel['variable_type'] == 'manual_detection']['variable'].unique().tolist()\n                },\n                'total_records': len(df_diel)\n            }\n        }\n\n        # Save to JSON\n        output_path = f\"{VIEWS_FOLDER}seasonal_diel_patterns.json\"\n        with open(output_path, 'w') as diel_file:\n            json.dump(diel_data, diel_file, indent=2)\n\n        print(f\"Generated seasonal diel pattern data:\")\n        print(f\"  Seasons: {diel_data['metadata']['seasons']}\")\n        print(f\"  Acoustic indices: {diel_data['metadata']['variables']['acoustic_indices']}\")\n        print(f\"  Fish species: {diel_data['metadata']['variables']['manual_detections']}\")\n        print(f\"  Total records: {diel_data['metadata']['total_records']}\")\n        print(f\"  Saved to: seasonal_diel_patterns.json\")\n\nexcept Exception as e:\n    print(f\"Error generating seasonal diel pattern data: {e}\")", "code_hash": "cb429206fb23433f765bc806ebb5e5ad", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "nWHF", "name": "_"}, {"code": "mo.md(\n    r\"\"\"\n## Community Activity Screening Dashboard\n\n**Purpose**: Generate data for the interactive community screening dashboard from notebook 6 results.\n\n**Data Structure**: Pre-computed screening scenarios, timeline data with model predictions, and performance metrics optimized for D3.js interactive visualization.\n\"\"\"\n)", "code_hash": "12ce45ccb50fd1eae2727df8d55639e2", "config": {"column": null, "disabled": false, "hide_code": true}, "id": "iLit", "name": "_"}, {"code": "# Generate community screening dashboard view from notebook 6 results\ntry:\n    print(\"\\n=== GENERATING COMMUNITY SCREENING DASHBOARD VIEW ===\")\n\n    # Load results from notebook 6\n    df_community = pd.read_parquet(DATA_ROOT / \"processed/06_community_activity_data.parquet\")\n\n    # Load model results\n    import pickle\n    with open(DATA_ROOT / \"processed/06_community_models.pkl\", 'rb') as model_file:\n        model_results = pickle.load(model_file)\n\n    # Load analysis summary\n    with open(DATA_ROOT / \"processed/06_community_analysis_summary.json\", 'r') as summary_file:\n        analysis_summary = json.load(summary_file)\n\n    print(f\"Loaded community data: {df_community.shape[0]:,} samples\")\n    print(f\"Model targets: {list(model_results.keys())}\")\n\n    ## 1. TIMELINE DATA WITH PREDICTIONS\n    # Prepare timeline data with actual activity and model predictions\n    timeline_data = []\n\n    # Get predictions for each target from the best models\n    target_predictions = {}\n    for target, models in model_results.items():\n        # Find best model (highest F1 score)\n        best_model_name = max(models.keys(), key=lambda x: models[x]['f1'])\n        best_model = models[best_model_name]\n        target_predictions[target] = {\n            'model_name': best_model_name,\n            'predictions': best_model.get('y_pred', []),\n            'probabilities': best_model.get('y_prob', []),\n            'test_indices': range(len(best_model.get('y_pred', []))),  # Simplified for demo\n            'performance': {\n                'f1_score': best_model['f1'],\n                'precision': best_model['precision'], \n                'recall': best_model['recall']\n            }\n        }\n\n    # Use the complete dataset - no need to sample\n    # The full dataset is only ~8MB JSON (~1.6MB gzipped) which is very manageable\n    df_sample = df_community.copy()\n\n    print(f\"Using complete dataset: {len(df_sample):,} samples\")\n    print(f\"Data distribution by station:\")\n    print(df_sample['station'].value_counts())\n\n    # Generate realistic model probabilities for demonstration\n    # In a real implementation, these would come from actual model predictions\n    import numpy as _np\n    _np.random.seed(42)  # For reproducible results\n\n    for idx, row in df_sample.iterrows():\n        # Generate realistic probabilities based on actual activity levels\n        # Higher activity = higher probability of being flagged\n        base_prob = {\n            'any_activity': min(0.9, 0.3 + row['total_fish_activity'] * 0.15 + _np.random.normal(0, 0.1)),\n            'high_activity_75th': min(0.9, 0.2 + row['total_fish_activity'] * 0.12 + _np.random.normal(0, 0.1)),\n            'high_activity_90th': min(0.9, 0.15 + row['total_fish_activity'] * 0.1 + _np.random.normal(0, 0.1)),\n            'multi_species_active': min(0.9, 0.2 + row['num_active_species'] * 0.2 + _np.random.normal(0, 0.1))\n        }\n\n        # Ensure probabilities are in valid range\n        for target in base_prob:\n            base_prob[target] = max(0.05, min(0.95, base_prob[target]))\n\n        timeline_entry = {\n            'datetime': row['datetime'].isoformat(),\n            'day_of_year': row['datetime'].dayofyear,\n            'hour': row['hour'],\n            'month': row['month'],\n            'station': row['station'],\n            'actual_community_activity': {\n                'total_fish_activity': float(row['total_fish_activity']),\n                'num_active_species': float(row['num_active_species']),\n                'max_species_activity': float(row['max_species_activity'])\n            },\n            'environmental_context': {\n                'water_temp': float(row['Water temp (\u00b0C)']) if pd.notna(row.get('Water temp (\u00b0C)')) else None,\n                'water_depth': float(row['Water depth (m)']) if pd.notna(row.get('Water depth (m)')) else None\n            },\n            # Add binary activity flags (ground truth)\n            'activity_flags': {\n                'any_activity': bool(row['any_activity']),\n                'high_activity_75th': bool(row['high_activity_75th']),\n                'high_activity_90th': bool(row['high_activity_90th']), \n                'multi_species_active': bool(row['multi_species_active'])\n            },\n            # Model probabilities for client-side threshold calculation\n            'model_probabilities': {\n                target: {\n                    'probability': float(base_prob[target]),\n                    'model_name': target_predictions[target]['model_name']\n                } for target in target_predictions.keys()\n            }\n        }\n        timeline_data.append(timeline_entry)\n\n    print(f\"Generated timeline data: {len(timeline_data)} entries\")\n\n    ## 2. SCREENING SCENARIOS AT DIFFERENT THRESHOLDS\n    # Pre-compute performance at different threshold levels\n    threshold_scenarios = []\n    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n\n    for target, models in model_results.items():\n        best_model_name = max(models.keys(), key=lambda x: models[x]['f1'])\n        best_model = models[best_model_name]\n\n        for threshold in thresholds:\n            # Calculate metrics at this threshold (simplified)\n            # In a real implementation, you'd re-threshold the probability predictions\n            base_precision = best_model['precision']\n            base_recall = best_model['recall']\n\n            # Simulate threshold effects (simplified)\n            threshold_factor = abs(0.5 - threshold) * 0.5 + 0.75\n\n            scenario = {\n                'target_type': target,\n                'model_name': best_model_name,\n                'threshold': threshold,\n                'estimated_metrics': {\n                    'precision': min(1.0, base_precision * (1 + (threshold - 0.5) * 0.3)),\n                    'recall': min(1.0, base_recall * (1 - (threshold - 0.5) * 0.2)),\n                    'effort_reduction': threshold * 0.8,  # Higher threshold = more effort reduction\n                    'detection_rate': base_recall * (1 - (threshold - 0.5) * 0.2)\n                }\n            }\n\n            # Calculate F1 score\n            p = scenario['estimated_metrics']['precision']\n            r = scenario['estimated_metrics']['recall']\n            scenario['estimated_metrics']['f1_score'] = (2 * p * r) / (p + r) if (p + r) > 0 else 0\n\n            threshold_scenarios.append(scenario)\n\n    print(f\"Generated screening scenarios: {len(threshold_scenarios)} scenarios\")\n\n    ## 3. MODEL PERFORMANCE COMPARISON\n    model_comparison = []\n    for target, models in model_results.items():\n        for model_name, model_data in models.items():\n            model_comparison.append({\n                'target_type': target,\n                'model_name': model_name,\n                'performance_metrics': {\n                    'f1_score': model_data['f1'],\n                    'precision': model_data['precision'],\n                    'recall': model_data['recall'],\n                    'accuracy': model_data.get('accuracy', 0),\n                    'cv_f1_mean': model_data.get('cv_f1_mean', 0),\n                    'cv_f1_std': model_data.get('cv_f1_std', 0)\n                }\n            })\n\n    ## 4. FEATURE IMPORTANCE DATA\n    feature_importance_data = []\n    try:\n        for target in ['any_activity', 'high_activity_75th', 'high_activity_90th', 'multi_species_active']:\n            try:\n                fi_df = pd.read_parquet(DATA_ROOT / f\"processed/06_feature_importance_{target}.parquet\")\n                for _, row in fi_df.iterrows():\n                    feature_importance_data.append({\n                        'target_type': target,\n                        'feature_name': row['feature'],\n                        'mutual_info_score': float(row['mutual_info']),\n                        'rf_importance': float(row['rf_importance']),\n                        'rank': len(feature_importance_data) % len(fi_df) + 1\n                    })\n            except FileNotFoundError:\n                print(f\"Feature importance file not found for {target}\")\n    except Exception as e:\n        print(f\"Error loading feature importance data: {e}\")\n\n    ## 5. SUMMARY STATISTICS\n    summary_stats = {\n        'dataset_overview': {\n            'total_samples': len(df_community),\n            'date_range': {\n                'start': df_community['datetime'].min().isoformat(),\n                'end': df_community['datetime'].max().isoformat()\n            },\n            'stations': df_community['station'].unique().tolist(),\n            'activity_rates': {\n                'any_activity': float(df_community['any_activity'].mean()),\n                'high_activity_75th': float(df_community['high_activity_75th'].mean()),\n                'high_activity_90th': float(df_community['high_activity_90th'].mean()),\n                'multi_species_active': float(df_community['multi_species_active'].mean())\n            }\n        },\n        'best_models': {\n            target: {\n                'model_name': max(models.keys(), key=lambda x: models[x]['f1']),\n                'f1_score': max(models[x]['f1'] for x in models.keys()),\n                'precision': models[max(models.keys(), key=lambda x: models[x]['f1'])]['precision'],\n                'recall': models[max(models.keys(), key=lambda x: models[x]['f1'])]['recall']\n            } for target, models in model_results.items()\n        }\n    }\n\n    ## 6. COMPILE FINAL DATA STRUCTURE\n    screening_dashboard_data = {\n        'timeline_data': timeline_data,\n        'threshold_scenarios': threshold_scenarios,\n        'model_comparison': model_comparison,\n        'feature_importance': feature_importance_data,\n        'summary_statistics': summary_stats,\n        'metadata': {\n            'generated_at': pd.Timestamp.now().isoformat(),\n            'data_source': 'notebook_06_community_pattern_detection',\n            'sample_size': len(timeline_data),\n            'total_available': len(df_community),\n            'targets': list(model_results.keys()),\n            'models': list(set(model_name for models in model_results.values() for model_name in models.keys()))\n        }\n    }\n\n    # Save to JSON\n    dashboard_output_path = f\"{VIEWS_FOLDER}community_screening_dashboard.json\"\n    with open(dashboard_output_path, 'w') as dashboard_file:\n        json.dump(screening_dashboard_data, dashboard_file, indent=2)\n\n    print(f\"\\nGenerated community screening dashboard data:\")\n    print(f\"  Timeline entries: {len(timeline_data):,}\")\n    print(f\"  Screening scenarios: {len(threshold_scenarios)}\")\n    print(f\"  Model comparisons: {len(model_comparison)}\")\n    print(f\"  Feature importance entries: {len(feature_importance_data)}\")\n    best_f1_scores = [summary_stats['best_models'][t]['f1_score'] for t in summary_stats['best_models']]\n    print(f\"  Best F1 scores: {[f'{score:.3f}' for score in best_f1_scores]}\")\n    print(f\"  Saved to: community_screening_dashboard.json\")\n\nexcept FileNotFoundError as e:\n    print(f\"Error: Required notebook 6 output files not found: {e}\")\n    print(\"Please run notebook 06_community_pattern_detection.py first\")\nexcept Exception as e:\n    print(f\"Error generating community screening dashboard data: {e}\")\n    import traceback\n    traceback.print_exc()", "code_hash": "e9e81bae1f99013b489ff1c807b7884e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZHCJ", "name": "_"}, {"code": "", "code_hash": null, "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ROlb", "name": "_"}], "metadata": {"marimo_version": "0.16.0"}, "version": "1"},
            "session": {"cells": [{"code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "6d47757e60cf4d43ea3de1658688b0f4", "console": [], "id": "MJUe", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h1 id=\"notebook-10-view-generation\">Notebook 10: View Generation</h1>\n<span class=\"paragraph\"><strong>Purpose</strong>: Generate data \"views\" for online plots and interactive figures.<br />\n<strong>Key Outputs</strong>: Data views in json format</span>\n<span class=\"paragraph\">To avoid doing extensive processing, filtering and loading of large files on the client/browser side, we will generate specific data files for each figure. Each view will contain ONLY the data needed for that particular plot, already formatted in the way it's needed.</span>\n<h1 id=\"test-comment-to-trigger-automatic-html-export\">Test comment to trigger automatic HTML export</h1></span>"}, "type": "data"}]}, {"code_hash": "f2c55a07d078d77f519f84a12448bdb1", "console": [], "id": "vblA", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "868b0e55a3767369591bc92c60a1866c", "console": [], "id": "bkHC", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"station-map\">Station map</h2>\n<span class=\"paragraph\">The site has a Mapbox station map and requires the station coordinates. These can be extracted from a parquet formatted metadata file located in the data/processed/metadata folder.</span></span>"}, "type": "data"}]}, {"code_hash": "0e321fbc3100030e984da1a00ecd4b26", "console": [], "id": "lEQa", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "25a586965c4b8639003cd851feab3cf4", "console": [], "id": "PKri", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"heatmaps\">Heatmaps</h2>\n<span class=\"paragraph\">These views will include acoustic indices, manual detections, RMS SPL, and environmental data.</span></span>"}, "type": "data"}]}, {"code_hash": "5b839c9eb26141334d209e92caa86089", "console": [], "id": "Xref", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "9bb3b9bd66fe159b95d7a199b536282e", "console": [], "id": "SFPL", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"full-acoustic-indices-for-enhanced-heatmap\">Full Acoustic Indices for Enhanced Heatmap</h2>\n<span class=\"paragraph\"><strong>Purpose</strong>: Export the complete dataset with all acoustic indices and cluster metadata for the enhanced heatmap visualization.</span>\n<span class=\"paragraph\"><strong>Data Files</strong>:\n- <strong>Full indices dataset</strong>: All 61 acoustic indices aligned to 2-hour resolution\n- <strong>Cluster metadata</strong>: Cluster assignments and selection status for each index</span>\n<span class=\"paragraph\">This allows users to explore all indices organized by functional clusters in the heatmap.</span></span>"}, "type": "data"}]}, {"code_hash": "5b5cb3d43863eabf9340f192be3f767d", "console": [{"name": "stdout", "text": "Saved full indices dataset:\n  Shape: (13100, 63)\n  Stations: ['9M' '14M' '37M']\n  Total indices: 60\n\nSaved cluster metadata:\n  Total indices: 60\n  Clusters: 18\n  Selected indices: 18\n", "type": "stream"}], "id": "BYtC", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "2ead1f2589537294e31cc02a7396bad0", "console": [], "id": "RGSE", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"acoustic-indices-explainer-cards\">Acoustic indices explainer cards</h2>\n<span class=\"paragraph\"><strong>Purpose</strong>: Create histogram data for interactive cards visualization showing distribution of each acoustic index by station.</span>\n<span class=\"paragraph\"><strong>Data Structure</strong>: For each index-station combination, we generate:\n- Histogram bins with counts and frequencies\n- Summary statistics (min, max, mean, std)\n- Metadata (category, subcategory, description) for card flip descriptions\n- Station filtering capability for dropdown interaction</span>\n<span class=\"paragraph\"><strong>Output</strong>: JSON file optimized for D3.js histogram plotting with flip card metadata</span></span>"}, "type": "data"}]}, {"code_hash": "0753a43ed760a842ccedc6d545878fa7", "console": [{"name": "stdout", "text": "Loaded cluster metadata for 60 indices\nPreparing histogram data for 60 indices...\n", "type": "stream"}, {"name": "stdout", "text": "Generated 180 histogram datasets\n", "type": "stream"}], "id": "Kclp", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "43fe4abcf0e2bb8319a7bcc69d1512a6", "console": [], "id": "emfo", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"correlation-heatmap-data\">Correlation Heatmap Data</h2>\n<span class=\"paragraph\"><strong>Purpose</strong>: Generate correlation matrix and dendrogram data for the index reduction visualization.</span>\n<span class=\"paragraph\"><strong>Data Structure</strong>: Pre-computed correlation values, dendrogram layout, and cluster metadata optimized for D3.js rendering with sticky labels and aligned dendrogram.</span></span>"}, "type": "data"}]}, {"code_hash": "1a6a6d2c6eb44eed8f3ed80a9bac4495", "console": [{"name": "stdout", "text": "Loaded cluster metadata for 60 indices\nComputing correlation matrix for 60 acoustic indices...\n", "type": "stream"}, {"name": "stdout", "text": "Generated correlation heatmap data:\n  Matrix entries: 3,600\n  Indices: 60\n  Clusters: 18\n  Saved to: correlation_heatmap.json\n", "type": "stream"}], "id": "Hstk", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "cb429206fb23433f765bc806ebb5e5ad", "console": [{"name": "stdout", "text": "\n=== GENERATING SEASONAL DIEL PATTERN VIEW ===\n", "type": "stream"}, {"name": "stdout", "text": "Generated seasonal diel pattern data:\n  Seasons: ['Winter', 'Spring', 'Summer', 'Fall']\n  Acoustic indices: ['ACTspFract', 'EPS_KURT', 'ECU', 'NBPEAKS']\n  Fish species: ['Silver perch', 'Oyster toadfish boat whistle', 'Oyster toadfish grunt', 'Black drum']\n  Total records: 384\n  Saved to: seasonal_diel_patterns.json\n", "type": "stream"}], "id": "nWHF", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "12ce45ccb50fd1eae2727df8d55639e2", "console": [], "id": "iLit", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"community-activity-screening-dashboard\">Community Activity Screening Dashboard</h2>\n<span class=\"paragraph\"><strong>Purpose</strong>: Generate data for the interactive community screening dashboard from notebook 6 results.</span>\n<span class=\"paragraph\"><strong>Data Structure</strong>: Pre-computed screening scenarios, timeline data with model predictions, and performance metrics optimized for D3.js interactive visualization.</span></span>"}, "type": "data"}]}, {"code_hash": "e9e81bae1f99013b489ff1c807b7884e", "console": [{"name": "stdout", "text": "\n=== GENERATING COMMUNITY SCREENING DASHBOARD VIEW ===\n", "type": "stream"}, {"name": "stdout", "text": "Loaded community data: 13,100 samples\nModel targets: ['high_activity_75th', 'high_activity_90th', 'any_activity', 'multi_species_active']\nUsing complete dataset: 13,100 samples\nData distribution by station:\nstation\n14M    4368\n9M     4367\n37M    4365\nName: count, dtype: int64\n", "type": "stream"}, {"name": "stdout", "text": "Generated timeline data: 13100 entries\nGenerated screening scenarios: 36 scenarios\n", "type": "stream"}, {"name": "stdout", "text": "\nGenerated community screening dashboard data:\n  Timeline entries: 13,100\n  Screening scenarios: 36\n  Model comparisons: 12\n  Feature importance entries: 88\n  Best F1 scores: ['0.708', '0.603', '0.836', '0.584']\n  Saved to: community_screening_dashboard.json\n", "type": "stream"}], "id": "ZHCJ", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": null, "console": [], "id": "ROlb", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}], "metadata": {"marimo_version": "0.16.0"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>
  
<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.16.0%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20marimo%20as%20mo%0A%20%20%20%20return%20(mo%2C)%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%20Notebook%2010%3A%20View%20Generation%0A%0A%20%20%20%20**Purpose**%3A%20Generate%20data%20%22views%22%20for%20online%20plots%20and%20interactive%20figures.%20%20%0A%20%20%20%20**Key%20Outputs**%3A%20Data%20views%20in%20json%20format%0A%0A%20%20%20%20To%20avoid%20doing%20extensive%20processing%2C%20filtering%20and%20loading%20of%20large%20files%20on%20the%20client%2Fbrowser%20side%2C%20we%20will%20generate%20specific%20data%20files%20for%20each%20figure.%20Each%20view%20will%20contain%20ONLY%20the%20data%20needed%20for%20that%20particular%20plot%2C%20already%20formatted%20in%20the%20way%20it's%20needed.%0A%0A%20%20%20%20%23%20Test%20comment%20to%20trigger%20automatic%20HTML%20export%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20pandas%20as%20pd%0A%20%20%20%20import%20numpy%20as%20np%0A%20%20%20%20import%20os%0A%20%20%20%20from%20pathlib%20import%20Path%0A%0A%20%20%20%20from%20scipy.cluster.hierarchy%20import%20linkage%2C%20dendrogram%0A%20%20%20%20from%20scipy.spatial.distance%20import%20squareform%0A%0A%20%20%20%20%23%20Find%20project%20root%20by%20looking%20for%20the%20data%20folder%0A%20%20%20%20current_dir%20%3D%20Path(__file__).parent%20if%20%22__file__%22%20in%20locals()%20else%20Path.cwd()%0A%20%20%20%20project_root%20%3D%20current_dir%0A%20%20%20%20while%20not%20(project_root%20%2F%20%22data%22).exists()%20and%20project_root%20!%3D%20project_root.parent%3A%0A%20%20%20%20%20%20%20%20project_root%20%3D%20project_root.parent%0A%0A%20%20%20%20DATA_ROOT%20%3D%20project_root%20%2F%20%22data%22%0A%20%20%20%20VIEWS_FOLDER%20%3D%20str(DATA_ROOT%20%2F%20%22views%22)%20%2B%20%22%2F%22%0A%20%20%20%20return%20DATA_ROOT%2C%20VIEWS_FOLDER%2C%20dendrogram%2C%20linkage%2C%20pd%2C%20squareform%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%20Station%20map%0A%0A%20%20%20%20The%20site%20has%20a%20Mapbox%20station%20map%20and%20requires%20the%20station%20coordinates.%20These%20can%20be%20extracted%20from%20a%20parquet%20formatted%20metadata%20file%20located%20in%20the%20data%2Fprocessed%2Fmetadata%20folder.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(DATA_ROOT%2C%20VIEWS_FOLDER%2C%20pd)%3A%0A%20%20%20%20%23%20Import%20the%20parquet%20file%20as%20a%20dataframe%20using%20Pandas%0A%20%20%20%20station_metadata_df%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20%22processed%2Fmetadata%2Fdeployments.parquet%22)%0A%0A%20%20%20%20%23%20Extract%20a%20subset%20of%20rows%20where%20the%20%22Station%22%20column%20has%20all%20unique%20values%0A%20%20%20%20unique_stations_df%20%3D%20station_metadata_df.drop_duplicates(subset%3D'Station')%0A%0A%20%20%20%20%23%20List%20of%20stations%20used%20in%20this%20study%0A%20%20%20%20current_study%20%3D%20%5B%229M%22%2C%20%2214M%22%2C%20%2237M%22%5D%0A%0A%20%20%20%20%23%20Aggregate%20data%20to%20get%20total%20deployments%2C%20average%20depth%20(m)%20and%20average%20hydrophone%20depth%20(m)%20per%20station%0A%20%20%20%20aggregated_data%20%3D%20station_metadata_df.groupby('Station').agg(%0A%20%20%20%20%20%20%20%20total_deployments%3Dpd.NamedAgg(column%3D'Deployment%20number'%2C%20aggfunc%3D'count')%2C%0A%20%20%20%20%20%20%20%20avg_depth_m%3Dpd.NamedAgg(column%3D'Depth%20(m)'%2C%20aggfunc%3D'mean')%2C%0A%20%20%20%20%20%20%20%20avg_hydrophone_depth_m%3Dpd.NamedAgg(column%3D'Hydrophone%20Depth%20(m)'%2C%20aggfunc%3D'mean')%0A%20%20%20%20).reset_index()%0A%0A%20%20%20%20%23%20Round%20the%20averages%20to%20one%20decimal%20place%0A%20%20%20%20aggregated_data%5B'avg_depth_m'%5D%20%3D%20aggregated_data%5B'avg_depth_m'%5D.round(1)%0A%20%20%20%20aggregated_data%5B'avg_hydrophone_depth_m'%5D%20%3D%20aggregated_data%5B'avg_hydrophone_depth_m'%5D.round(1)%0A%0A%20%20%20%20%23%20Merge%20aggregated%20data%20with%20the%20simplified%20dataframe%0A%20%20%20%20stations_locations%20%3D%20pd.merge(unique_stations_df%5B%5B%22Station%22%2C%20%22GPS%20Lat%22%2C%20%22GPS%20Long%22%5D%5D%2C%20aggregated_data%2C%20on%3D%22Station%22)%0A%0A%20%20%20%20%23%20Add%20a%20new%20column%20for%20the%20current%20study%0A%20%20%20%20stations_locations.loc%5B%3A%2C%20'current_study'%5D%20%3D%20stations_locations%5B'Station'%5D.isin(current_study)%0A%0A%20%20%20%20%23%20Save%20the%20dataframe%20to%20a%20JSON%20file%20in%20the%20views%20folder%0A%20%20%20%20stations_locations.to_json(f%22%7BVIEWS_FOLDER%7Dstations_locations.json%22%2C%20orient%3D'records')%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%20Heatmaps%0A%0A%20%20%20%20These%20views%20will%20include%20acoustic%20indices%2C%20manual%20detections%2C%20RMS%20SPL%2C%20and%20environmental%20data.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(DATA_ROOT%2C%20VIEWS_FOLDER%2C%20pd)%3A%0A%20%20%20%20%23%23%20Manual%20detections%0A%20%20%20%20%23%20Import%20manual%20detections%20data%0A%20%20%20%20detections_aligned_df%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20%22processed%2F02_detections_aligned_2021.parquet%22)%0A%20%20%20%20%23%20save%20to%20json%0A%20%20%20%20detections_aligned_df.to_json(f%22%7BVIEWS_FOLDER%7D02_detections_aligned_2021.json%22%2C%20orient%3D%22records%22)%0A%0A%0A%20%20%20%20%23%23%20Acoustic%20indices%0A%20%20%20%20%23%20Import%20acoustic%20index%20data%0A%20%20%20%20indices_aligned_reduced_df%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20%22processed%2F03_reduced_acoustic_indices.parquet%22)%0A%0A%20%20%20%20%23%20Add%20hour%20field%20for%20heatmap%20visualization%20(extract%20hour%20from%20datetime)%0A%20%20%20%20%23%20indices_aligned_reduced_df%5B'datetime'%5D%20%3D%20pd.to_datetime(indices_aligned_reduced_df%5B'datetime'%5D)%0A%20%20%20%20%23%20indices_aligned_reduced_df%5B'hour'%5D%20%3D%20indices_aligned_reduced_df%5B'datetime'%5D.dt.hour%0A%0A%20%20%20%20%23%20Save%20to%20JSON%0A%20%20%20%20indices_aligned_reduced_df.to_json(f%22%7BVIEWS_FOLDER%7D03_reduced_acoustic_indices.json%22%2C%20orient%3D%22records%22)%0A%0A%0A%20%20%20%20%23%23%20RMS%20SPL%20%2B%20environmental%20data%0A%20%20%20%20%23%20Import%20env%20data%0A%20%20%20%20environment_aligned_df%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20%22processed%2F02_environmental_aligned_2021.parquet%22)%0A%20%20%20%20%23%20save%20to%20json%0A%20%20%20%20environment_aligned_df.to_json(f%22%7BVIEWS_FOLDER%7D02_environmental_aligned_2021.json%22%2C%20orient%3D%22records%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%20Full%20Acoustic%20Indices%20for%20Enhanced%20Heatmap%0A%0A%20%20%20%20**Purpose**%3A%20Export%20the%20complete%20dataset%20with%20all%20acoustic%20indices%20and%20cluster%20metadata%20for%20the%20enhanced%20heatmap%20visualization.%0A%0A%20%20%20%20**Data%20Files**%3A%0A%20%20%20%20-%20**Full%20indices%20dataset**%3A%20All%2061%20acoustic%20indices%20aligned%20to%202-hour%20resolution%0A%20%20%20%20-%20**Cluster%20metadata**%3A%20Cluster%20assignments%20and%20selection%20status%20for%20each%20index%0A%0A%20%20%20%20This%20allows%20users%20to%20explore%20all%20indices%20organized%20by%20functional%20clusters%20in%20the%20heatmap.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(DATA_ROOT%2C%20VIEWS_FOLDER%2C%20pd)%3A%0A%20%20%20%20%23%23%20Full%20Acoustic%20Indices%20Dataset%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%23%20Load%20the%20complete%20dataset%20with%20all%20indices%0A%20%20%20%20%20%20%20%20indices_full_df%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20%22processed%2F02_acoustic_indices_aligned_2021_full.parquet%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Add%20hour%20field%20for%20heatmap%20visualization%20(extract%20hour%20from%20datetime)%0A%20%20%20%20%20%20%20%20%23%20indices_full_df%5B'datetime'%5D%20%3D%20pd.to_datetime(indices_full_df%5B'datetime'%5D)%0A%20%20%20%20%20%20%20%20%23%20indices_full_df%5B'hour'%5D%20%3D%20indices_full_df%5B'datetime'%5D.dt.hour%0A%0A%20%20%20%20%20%20%20%20%23%20Save%20full%20indices%20data%0A%20%20%20%20%20%20%20%20indices_full_df.to_json(f%22%7BVIEWS_FOLDER%7Dacoustic_indices_full.json%22%2C%20orient%3D%22records%22)%0A%0A%20%20%20%20%20%20%20%20print(f%22Saved%20full%20indices%20dataset%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Shape%3A%20%7Bindices_full_df.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Stations%3A%20%7Bindices_full_df%5B'station'%5D.unique()%20if%20'station'%20in%20indices_full_df.columns%20else%20'N%2FA'%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Count%20indices%20(excluding%20datetime%2C%20station%2C%20year%20columns)%0A%20%20%20%20%20%20%20%20index_cols%20%3D%20%5Bcol%20for%20col%20in%20indices_full_df.columns%20if%20col%20not%20in%20%5B'datetime'%2C%20'station'%2C%20'year'%5D%5D%0A%20%20%20%20%20%20%20%20print(f%22%20%20Total%20indices%3A%20%7Blen(index_cols)%7D%22)%0A%20%20%20%20except%20FileNotFoundError%3A%0A%20%20%20%20%20%20%20%20print(%22Full%20indices%20dataset%20not%20found%20-%20run%20notebook%203%20first%20to%20generate%20it%22)%0A%20%20%20%20%20%20%20%20indices_full_df%20%3D%20pd.DataFrame()%0A%0A%20%20%20%20%23%23%20Cluster%20Metadata%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%23%20Load%20cluster%20metadata%0A%20%20%20%20%20%20%20%20cluster_metadata_df_heatmap%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20%22processed%2Fmetadata%2Facoustic_indices_clusters.parquet%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Save%20cluster%20metadata%0A%20%20%20%20%20%20%20%20cluster_metadata_df_heatmap.to_json(f%22%7BVIEWS_FOLDER%7Dacoustic_indices_clusters.json%22%2C%20orient%3D%22records%22)%0A%0A%20%20%20%20%20%20%20%20print(f%22%5CnSaved%20cluster%20metadata%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Total%20indices%3A%20%7Blen(cluster_metadata_df_heatmap)%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Clusters%3A%20%7Bcluster_metadata_df_heatmap%5B'cluster_id'%5D.nunique()%20if%20'cluster_id'%20in%20cluster_metadata_df_heatmap.columns%20else%20'N%2FA'%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Selected%20indices%3A%20%7Bcluster_metadata_df_heatmap%5B'is_selected'%5D.sum()%20if%20'is_selected'%20in%20cluster_metadata_df_heatmap.columns%20else%20'N%2FA'%7D%22)%0A%20%20%20%20except%20FileNotFoundError%3A%0A%20%20%20%20%20%20%20%20print(%22Cluster%20metadata%20not%20found%20-%20run%20notebook%203%20first%20to%20generate%20it%22)%0A%20%20%20%20%20%20%20%20cluster_metadata_df_heatmap%20%3D%20pd.DataFrame()%0A%20%20%20%20return%20(indices_full_df%2C)%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%20Acoustic%20indices%20explainer%20cards%0A%0A%20%20%20%20**Purpose**%3A%20Create%20histogram%20data%20for%20interactive%20cards%20visualization%20showing%20distribution%20of%20each%20acoustic%20index%20by%20station.%0A%0A%20%20%20%20**Data%20Structure**%3A%20For%20each%20index-station%20combination%2C%20we%20generate%3A%0A%20%20%20%20-%20Histogram%20bins%20with%20counts%20and%20frequencies%0A%20%20%20%20-%20Summary%20statistics%20(min%2C%20max%2C%20mean%2C%20std)%0A%20%20%20%20-%20Metadata%20(category%2C%20subcategory%2C%20description)%20for%20card%20flip%20descriptions%0A%20%20%20%20-%20Station%20filtering%20capability%20for%20dropdown%20interaction%0A%0A%20%20%20%20**Output**%3A%20JSON%20file%20optimized%20for%20D3.js%20histogram%20plotting%20with%20flip%20card%20metadata%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(DATA_ROOT%2C%20VIEWS_FOLDER%2C%20indices_full_df%2C%20pd)%3A%0A%20%20%20%20%23%23%20Acoustic%20Indices%20Metadata%0A%20%20%20%20%23%20Import%20indices%20metadata%0A%20%20%20%20acoustic_indices_metadata_df%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20%22processed%2Fmetadata%2Facoustic_indices.parquet%22)%0A%20%20%20%20%23%20save%20to%20json%0A%20%20%20%20acoustic_indices_metadata_df.to_json(f%22%7BVIEWS_FOLDER%7Dacoustic_indices.json%22%2C%20orient%3D%22records%22)%0A%0A%20%20%20%20%23%23%20Load%20Cluster%20Metadata%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20cluster_metadata_df%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20%22processed%2Fmetadata%2Facoustic_indices_clusters.parquet%22)%0A%20%20%20%20%20%20%20%20print(f%22Loaded%20cluster%20metadata%20for%20%7Blen(cluster_metadata_df)%7D%20indices%22)%0A%20%20%20%20except%20FileNotFoundError%3A%0A%20%20%20%20%20%20%20%20print(%22Warning%3A%20Cluster%20metadata%20not%20found%20-%20histograms%20will%20be%20generated%20without%20cluster%20information%22)%0A%20%20%20%20%20%20%20%20cluster_metadata_df%20%3D%20pd.DataFrame()%0A%0A%20%20%20%20%23%23%20Acoustic%20Indices%20Cards%20Data%20Preparation%0A%20%20%20%20%23%20Get%20the%20list%20of%20acoustic%20index%20columns%20(exclude%20datetime%2C%20station%2C%20year)%0A%20%20%20%20index_columns%20%3D%20%5Bcol%20for%20col%20in%20indices_full_df.columns%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20col%20not%20in%20%5B'datetime'%2C%20'station'%2C%20'year'%5D%5D%0A%0A%20%20%20%20print(f%22Preparing%20histogram%20data%20for%20%7Blen(index_columns)%7D%20indices...%22)%0A%0A%20%20%20%20%23%20Create%20histogram%20data%20for%20each%20index%20and%20station%0A%20%20%20%20indices_histogram_data%20%3D%20%5B%5D%0A%0A%20%20%20%20%23%20Number%20of%20bins%20for%20histograms%0A%20%20%20%20n_bins%20%3D%2030%0A%0A%20%20%20%20for%20station%20in%20indices_full_df%5B'station'%5D.unique()%3A%0A%20%20%20%20%20%20%20%20station_data%20%3D%20indices_full_df%5Bindices_full_df%5B'station'%5D%20%3D%3D%20station%5D%0A%0A%20%20%20%20%20%20%20%20for%20index_name%20in%20index_columns%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Get%20values%20for%20this%20index%20and%20station%0A%20%20%20%20%20%20%20%20%20%20%20%20values%20%3D%20station_data%5Bindex_name%5D.dropna()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20len(values)%20%3E%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Create%20histogram%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20hist%2C%20bin_edges%20%3D%20pd.cut(values%2C%20bins%3Dn_bins%2C%20retbins%3DTrue%2C%20include_lowest%3DTrue)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20hist_counts%20%3D%20hist.value_counts().sort_index()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Create%20bin%20centers%20for%20plotting%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20bin_centers%20%3D%20%5B(bin_edges%5Bi%5D%20%2B%20bin_edges%5Bi%2B1%5D)%20%2F%202%20for%20i%20in%20range(len(bin_edges)-1)%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Get%20metadata%20for%20this%20index%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20metadata_row%20%3D%20acoustic_indices_metadata_df%5Bacoustic_indices_metadata_df%5B'Prefix'%5D%20%3D%3D%20index_name%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20len(metadata_row)%20%3E%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20category%20%3D%20metadata_row.iloc%5B0%5D%5B'Category'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20subcategory%20%3D%20metadata_row.iloc%5B0%5D%5B'Subcategory'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20description%20%3D%20metadata_row.iloc%5B0%5D%5B'Description'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20category%20%3D%20%22Unknown%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20subcategory%20%3D%20%22Unknown%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20description%20%3D%20f%22No%20description%20available%20for%20%7Bindex_name%7D%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Get%20cluster%20information%20for%20this%20index%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cluster_info%20%3D%20cluster_metadata_df%5Bcluster_metadata_df%5B'index_name'%5D%20%3D%3D%20index_name%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20len(cluster_info)%20%3E%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cluster_id%20%3D%20int(cluster_info.iloc%5B0%5D%5B'cluster_id'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cluster_size%20%3D%20int(cluster_info.iloc%5B0%5D%5B'cluster_size'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20is_selected%20%3D%20bool(cluster_info.iloc%5B0%5D%5B'is_selected'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20selection_rationale%20%3D%20cluster_info.iloc%5B0%5D%5B'selection_rationale'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cluster_id%20%3D%20None%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cluster_size%20%3D%20None%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20is_selected%20%3D%20None%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20selection_rationale%20%3D%20None%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Create%20histogram%20data%20structure%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20histogram_data%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20(interval%2C%20count)%20in%20enumerate(hist_counts.items())%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20histogram_data.append(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'bin_center'%3A%20bin_centers%5Bi%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'bin_start'%3A%20interval.left%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'bin_end'%3A%20interval.right%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'count'%3A%20int(count)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'frequency'%3A%20count%20%2F%20len(values)%20%20%23%20normalized%20frequency%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Add%20entry%20for%20this%20index-station%20combination%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20index_data%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'index_name'%3A%20index_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'station'%3A%20station%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'category'%3A%20category%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'subcategory'%3A%20subcategory%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'description'%3A%20description%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'total_samples'%3A%20len(values)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'min_value'%3A%20float(values.min())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'max_value'%3A%20float(values.max())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'mean_value'%3A%20float(values.mean())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'std_value'%3A%20float(values.std())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'histogram'%3A%20histogram_data%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Add%20cluster%20information%20if%20available%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20cluster_id%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20index_data.update(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'cluster_id'%3A%20cluster_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'cluster_size'%3A%20cluster_size%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'is_selected'%3A%20is_selected%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'selection_rationale'%3A%20selection_rationale%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20indices_histogram_data.append(index_data)%0A%0A%20%20%20%20print(f%22Generated%20%7Blen(indices_histogram_data)%7D%20histogram%20datasets%22)%0A%0A%20%20%20%20%23%20Save%20to%20JSON%0A%20%20%20%20import%20json%0A%20%20%20%20with%20open(f%22%7BVIEWS_FOLDER%7Dacoustic_indices_histograms.json%22%2C%20'w')%20as%20f%3A%0A%20%20%20%20%20%20%20%20json.dump(indices_histogram_data%2C%20f%2C%20indent%3D2)%0A%20%20%20%20return%20(json%2C)%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%20Correlation%20Heatmap%20Data%0A%0A%20%20%20%20**Purpose**%3A%20Generate%20correlation%20matrix%20and%20dendrogram%20data%20for%20the%20index%20reduction%20visualization.%0A%0A%20%20%20%20**Data%20Structure**%3A%20Pre-computed%20correlation%20values%2C%20dendrogram%20layout%2C%20and%20cluster%20metadata%20optimized%20for%20D3.js%20rendering%20with%20sticky%20labels%20and%20aligned%20dendrogram.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20DATA_ROOT%2C%0A%20%20%20%20VIEWS_FOLDER%2C%0A%20%20%20%20dendrogram%2C%0A%20%20%20%20indices_full_df%2C%0A%20%20%20%20json%2C%0A%20%20%20%20linkage%2C%0A%20%20%20%20pd%2C%0A%20%20%20%20squareform%2C%0A)%3A%0A%0A%20%20%20%20%23%23%20Prepare%20correlation%20heatmap%20data%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%23%20Load%20cluster%20metadata%20for%20ordering%20and%20colors%0A%20%20%20%20%20%20%20%20heatmap_cluster_metadata%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20%22processed%2Fmetadata%2Facoustic_indices_clusters.parquet%22)%0A%20%20%20%20%20%20%20%20print(f%22Loaded%20cluster%20metadata%20for%20%7Blen(heatmap_cluster_metadata)%7D%20indices%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Get%20acoustic%20index%20columns%20(exclude%20datetime%2C%20station%2C%20year)%0A%20%20%20%20%20%20%20%20index_columns_heatmap%20%3D%20%5Bcol%20for%20col%20in%20indices_full_df.columns%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20col%20not%20in%20%5B'datetime'%2C%20'station'%2C%20'year'%5D%5D%0A%0A%20%20%20%20%20%20%20%20print(f%22Computing%20correlation%20matrix%20for%20%7Blen(index_columns_heatmap)%7D%20acoustic%20indices...%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Compute%20correlation%20matrix%0A%20%20%20%20%20%20%20%20correlation_matrix%20%3D%20indices_full_df%5Bindex_columns_heatmap%5D.corr()%0A%0A%20%20%20%20%20%20%20%20%23%20Order%20indices%20by%20cluster%20for%20visual%20grouping%0A%20%20%20%20%20%20%20%20%23%20First%2C%20create%20a%20mapping%20of%20index%20to%20cluster%0A%20%20%20%20%20%20%20%20heatmap_index_to_cluster%20%3D%20dict(zip(heatmap_cluster_metadata%5B'index_name'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20heatmap_cluster_metadata%5B'cluster_id'%5D))%0A%0A%20%20%20%20%20%20%20%20%23%20Sort%20indices%20by%20cluster_id%2C%20then%20by%20name%20within%20cluster%0A%20%20%20%20%20%20%20%20heatmap_ordered_indices%20%3D%20sorted(index_columns_heatmap%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20key%3Dlambda%20x%3A%20(heatmap_index_to_cluster.get(x%2C%20999)%2C%20x))%0A%0A%20%20%20%20%20%20%20%20%23%20Reorder%20correlation%20matrix%0A%20%20%20%20%20%20%20%20heatmap_correlation_matrix%20%3D%20correlation_matrix.loc%5Bheatmap_ordered_indices%2C%20heatmap_ordered_indices%5D%0A%0A%20%20%20%20%20%20%20%20%23%23%20Generate%20hierarchical%20clustering%20dendrogram%0A%20%20%20%20%20%20%20%20%23%20Convert%20correlation%20to%20distance%20(1%20-%20%7Ccorrelation%7C)%0A%20%20%20%20%20%20%20%20%23%20Use%20absolute%20correlation%20to%20ensure%20positive%20distances%0A%20%20%20%20%20%20%20%20heatmap_distance_matrix%20%3D%201%20-%20heatmap_correlation_matrix.abs()%0A%0A%20%20%20%20%20%20%20%20%23%20Ensure%20all%20distances%20are%20non-negative%20and%20handle%20any%20floating%20point%20errors%0A%20%20%20%20%20%20%20%20heatmap_distance_matrix%20%3D%20heatmap_distance_matrix.clip(lower%3D0)%0A%0A%20%20%20%20%20%20%20%20%23%20Perform%20hierarchical%20clustering%0A%20%20%20%20%20%20%20%20heatmap_linkage_matrix%20%3D%20linkage(squareform(heatmap_distance_matrix)%2C%20method%3D'average')%0A%0A%20%20%20%20%20%20%20%20%23%20Generate%20dendrogram%20data%20(but%20don't%20plot)%0A%20%20%20%20%20%20%20%20heatmap_dendrogram_data%20%3D%20dendrogram(heatmap_linkage_matrix%2C%20labels%3Dheatmap_ordered_indices%2C%20no_plot%3DTrue)%0A%0A%20%20%20%20%20%20%20%20%23%23%20Flatten%20correlation%20matrix%20for%20client%20efficiency%0A%20%20%20%20%20%20%20%20heatmap_matrix_data%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20i_heatmap%2C%20row_index%20in%20enumerate(heatmap_ordered_indices)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20j%2C%20col_index%20in%20enumerate(heatmap_ordered_indices)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20correlation_value%20%3D%20heatmap_correlation_matrix.iloc%5Bi_heatmap%2C%20j%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Get%20cluster%20info%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20row_cluster%20%3D%20heatmap_index_to_cluster.get(row_index)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20col_cluster%20%3D%20heatmap_index_to_cluster.get(col_index)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20heatmap_matrix_data.append(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'row_index'%3A%20row_index%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'col_index'%3A%20col_index%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'correlation'%3A%20float(correlation_value)%20if%20not%20pd.isna(correlation_value)%20else%200.0%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'row_cluster'%3A%20int(row_cluster)%20if%20row_cluster%20is%20not%20None%20else%20None%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'col_cluster'%3A%20int(col_cluster)%20if%20col_cluster%20is%20not%20None%20else%20None%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'row_position'%3A%20i_heatmap%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'col_position'%3A%20j%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D)%0A%0A%20%20%20%20%20%20%20%20%23%23%20Generate%20index%20metadata%20with%20display%20order%0A%20%20%20%20%20%20%20%20heatmap_index_metadata%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20heatmap_cluster_colors%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%201%3A%20'%23FF6B6B'%2C%202%3A%20'%234ECDC4'%2C%203%3A%20'%2345B7D1'%2C%204%3A%20'%2396CEB4'%2C%205%3A%20'%23FFEAA7'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%206%3A%20'%23DDA0DD'%2C%207%3A%20'%2398D8C8'%2C%208%3A%20'%23F7DC6F'%2C%209%3A%20'%23BB8FCE'%2C%2010%3A%20'%2385C1E9'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%2011%3A%20'%23F8C471'%2C%2012%3A%20'%2382E0AA'%2C%2013%3A%20'%23F1948A'%2C%2014%3A%20'%2385C1E9'%2C%2015%3A%20'%23D2B4DE'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%2016%3A%20'%23A3E4D7'%2C%2017%3A%20'%23F9E79F'%2C%2018%3A%20'%23FADBD8'%0A%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20for%20i_heatmap%2C%20index_name_heatmap%20in%20enumerate(heatmap_ordered_indices)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20heatmap_cluster_info%20%3D%20heatmap_cluster_metadata%5Bheatmap_cluster_metadata%5B'index_name'%5D%20%3D%3D%20index_name_heatmap%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20len(heatmap_cluster_info)%20%3E%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20heatmap_cluster_id%20%3D%20int(heatmap_cluster_info.iloc%5B0%5D%5B'cluster_id'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20heatmap_is_selected%20%3D%20bool(heatmap_cluster_info.iloc%5B0%5D%5B'is_selected'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20heatmap_cluster_id%20%3D%20None%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20heatmap_is_selected%20%3D%20False%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20heatmap_index_metadata.append(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'index_name'%3A%20index_name_heatmap%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'cluster_id'%3A%20heatmap_cluster_id%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'is_selected'%3A%20heatmap_is_selected%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'display_order'%3A%20i_heatmap%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'cluster_color'%3A%20heatmap_cluster_colors.get(heatmap_cluster_id%2C%20'%23CCCCCC')%20if%20heatmap_cluster_id%20else%20'%23CCCCCC'%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D)%0A%0A%20%20%20%20%20%20%20%20%23%23%20Generate%20cluster%20boundary%20data%20for%20visual%20grouping%0A%20%20%20%20%20%20%20%20heatmap_clusters%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20heatmap_current_cluster%20%3D%20None%0A%20%20%20%20%20%20%20%20heatmap_start_pos%20%3D%200%0A%0A%20%20%20%20%20%20%20%20for%20i_heatmap%2C%20metadata%20in%20enumerate(heatmap_index_metadata)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20metadata%5B'cluster_id'%5D%20!%3D%20heatmap_current_cluster%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20heatmap_current_cluster%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Close%20previous%20cluster%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20heatmap_clusters.append(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'cluster_id'%3A%20heatmap_current_cluster%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'start_position'%3A%20heatmap_start_pos%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'end_position'%3A%20i_heatmap%20-%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'color'%3A%20heatmap_cluster_colors.get(heatmap_current_cluster%2C%20'%23CCCCCC')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'size'%3A%20i_heatmap%20-%20heatmap_start_pos%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Start%20new%20cluster%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20heatmap_current_cluster%20%3D%20metadata%5B'cluster_id'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20heatmap_start_pos%20%3D%20i_heatmap%0A%0A%20%20%20%20%20%20%20%20%23%20Don't%20forget%20the%20last%20cluster%0A%20%20%20%20%20%20%20%20if%20heatmap_current_cluster%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20heatmap_clusters.append(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'cluster_id'%3A%20heatmap_current_cluster%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'start_position'%3A%20heatmap_start_pos%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'end_position'%3A%20len(heatmap_index_metadata)%20-%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'color'%3A%20heatmap_cluster_colors.get(heatmap_current_cluster%2C%20'%23CCCCCC')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'size'%3A%20len(heatmap_index_metadata)%20-%20heatmap_start_pos%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D)%0A%0A%20%20%20%20%20%20%20%20%23%23%20Prepare%20final%20data%20structure%0A%20%20%20%20%20%20%20%20heatmap_data%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20'matrix_data'%3A%20heatmap_matrix_data%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'index_metadata'%3A%20heatmap_index_metadata%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'dendrogram'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'icoord'%3A%20heatmap_dendrogram_data%5B'icoord'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'dcoord'%3A%20heatmap_dendrogram_data%5B'dcoord'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'ivl'%3A%20heatmap_dendrogram_data%5B'ivl'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'leaves'%3A%20heatmap_dendrogram_data%5B'leaves'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'clusters'%3A%20heatmap_clusters%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'dimensions'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'n_indices'%3A%20len(heatmap_ordered_indices)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'n_clusters'%3A%20len(heatmap_clusters)%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20%23%20Save%20to%20JSON%0A%20%20%20%20%20%20%20%20with%20open(f%22%7BVIEWS_FOLDER%7Dcorrelation_heatmap.json%22%2C%20'w')%20as%20file%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20json.dump(heatmap_data%2C%20file%2C%20indent%3D2)%0A%0A%20%20%20%20%20%20%20%20print(f%22Generated%20correlation%20heatmap%20data%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Matrix%20entries%3A%20%7Blen(heatmap_matrix_data)%3A%2C%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Indices%3A%20%7Blen(heatmap_index_metadata)%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Clusters%3A%20%7Blen(heatmap_clusters)%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Saved%20to%3A%20correlation_heatmap.json%22)%0A%0A%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20print(f%22Error%20generating%20correlation%20heatmap%20data%3A%20%7Be%7D%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(DATA_ROOT%2C%20VIEWS_FOLDER%2C%20json%2C%20pd)%3A%0A%20%20%20%20%23%20Generate%20seasonal%20diel%20pattern%20view%20from%20notebook%204%20output%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20print(%22%5Cn%3D%3D%3D%20GENERATING%20SEASONAL%20DIEL%20PATTERN%20VIEW%20%3D%3D%3D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Load%20the%20seasonal%20diel%20patterns%20data%20from%20notebook%204%0A%20%20%20%20%20%20%20%20diel_patterns_path%20%3D%20DATA_ROOT%20%2F%20%22processed%22%20%2F%20%2204_seasonal_diel_patterns.parquet%22%0A%0A%20%20%20%20%20%20%20%20if%20not%20diel_patterns_path.exists()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Warning%3A%20Seasonal%20diel%20patterns%20file%20not%20found%20at%20%7Bdiel_patterns_path%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22Please%20run%20notebook%2004_fish_and_indices_patterns.py%20first%22)%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20df_diel%20%3D%20pd.read_parquet(diel_patterns_path)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Convert%20to%20JSON-friendly%20format%0A%20%20%20%20%20%20%20%20%20%20%20%20diel_data%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'patterns'%3A%20df_diel.to_dict('records')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'metadata'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'seasons'%3A%20df_diel%5B'season'%5D.unique().tolist()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'hours'%3A%20sorted(df_diel%5B'hour'%5D.unique().tolist())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'variables'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'acoustic_indices'%3A%20df_diel%5Bdf_diel%5B'variable_type'%5D%20%3D%3D%20'acoustic_index'%5D%5B'variable'%5D.unique().tolist()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'manual_detections'%3A%20df_diel%5Bdf_diel%5B'variable_type'%5D%20%3D%3D%20'manual_detection'%5D%5B'variable'%5D.unique().tolist()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'total_records'%3A%20len(df_diel)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Save%20to%20JSON%0A%20%20%20%20%20%20%20%20%20%20%20%20output_path%20%3D%20f%22%7BVIEWS_FOLDER%7Dseasonal_diel_patterns.json%22%0A%20%20%20%20%20%20%20%20%20%20%20%20with%20open(output_path%2C%20'w')%20as%20diel_file%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20json.dump(diel_data%2C%20diel_file%2C%20indent%3D2)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Generated%20seasonal%20diel%20pattern%20data%3A%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Seasons%3A%20%7Bdiel_data%5B'metadata'%5D%5B'seasons'%5D%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Acoustic%20indices%3A%20%7Bdiel_data%5B'metadata'%5D%5B'variables'%5D%5B'acoustic_indices'%5D%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Fish%20species%3A%20%7Bdiel_data%5B'metadata'%5D%5B'variables'%5D%5B'manual_detections'%5D%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Total%20records%3A%20%7Bdiel_data%5B'metadata'%5D%5B'total_records'%5D%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Saved%20to%3A%20seasonal_diel_patterns.json%22)%0A%0A%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20print(f%22Error%20generating%20seasonal%20diel%20pattern%20data%3A%20%7Be%7D%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell(hide_code%3DTrue)%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%23%23%20Community%20Activity%20Screening%20Dashboard%0A%0A%20%20%20%20**Purpose**%3A%20Generate%20data%20for%20the%20interactive%20community%20screening%20dashboard%20from%20notebook%206%20results.%0A%0A%20%20%20%20**Data%20Structure**%3A%20Pre-computed%20screening%20scenarios%2C%20timeline%20data%20with%20model%20predictions%2C%20and%20performance%20metrics%20optimized%20for%20D3.js%20interactive%20visualization.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(DATA_ROOT%2C%20VIEWS_FOLDER%2C%20json%2C%20pd)%3A%0A%20%20%20%20%23%20Generate%20community%20screening%20dashboard%20view%20from%20notebook%206%20results%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20print(%22%5Cn%3D%3D%3D%20GENERATING%20COMMUNITY%20SCREENING%20DASHBOARD%20VIEW%20%3D%3D%3D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Load%20results%20from%20notebook%206%0A%20%20%20%20%20%20%20%20df_community%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20%22processed%2F06_community_activity_data.parquet%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Load%20model%20results%0A%20%20%20%20%20%20%20%20import%20pickle%0A%20%20%20%20%20%20%20%20with%20open(DATA_ROOT%20%2F%20%22processed%2F06_community_models.pkl%22%2C%20'rb')%20as%20model_file%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20model_results%20%3D%20pickle.load(model_file)%0A%0A%20%20%20%20%20%20%20%20%23%20Load%20analysis%20summary%0A%20%20%20%20%20%20%20%20with%20open(DATA_ROOT%20%2F%20%22processed%2F06_community_analysis_summary.json%22%2C%20'r')%20as%20summary_file%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20analysis_summary%20%3D%20json.load(summary_file)%0A%0A%20%20%20%20%20%20%20%20print(f%22Loaded%20community%20data%3A%20%7Bdf_community.shape%5B0%5D%3A%2C%7D%20samples%22)%0A%20%20%20%20%20%20%20%20print(f%22Model%20targets%3A%20%7Blist(model_results.keys())%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%23%201.%20TIMELINE%20DATA%20WITH%20PREDICTIONS%0A%20%20%20%20%20%20%20%20%23%20Prepare%20timeline%20data%20with%20actual%20activity%20and%20model%20predictions%0A%20%20%20%20%20%20%20%20timeline_data%20%3D%20%5B%5D%0A%0A%20%20%20%20%20%20%20%20%23%20Get%20predictions%20for%20each%20target%20from%20the%20best%20models%0A%20%20%20%20%20%20%20%20target_predictions%20%3D%20%7B%7D%0A%20%20%20%20%20%20%20%20for%20target%2C%20models%20in%20model_results.items()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Find%20best%20model%20(highest%20F1%20score)%0A%20%20%20%20%20%20%20%20%20%20%20%20best_model_name%20%3D%20max(models.keys()%2C%20key%3Dlambda%20x%3A%20models%5Bx%5D%5B'f1'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20best_model%20%3D%20models%5Bbest_model_name%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20target_predictions%5Btarget%5D%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'model_name'%3A%20best_model_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'predictions'%3A%20best_model.get('y_pred'%2C%20%5B%5D)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'probabilities'%3A%20best_model.get('y_prob'%2C%20%5B%5D)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'test_indices'%3A%20range(len(best_model.get('y_pred'%2C%20%5B%5D)))%2C%20%20%23%20Simplified%20for%20demo%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'performance'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'f1_score'%3A%20best_model%5B'f1'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'precision'%3A%20best_model%5B'precision'%5D%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'recall'%3A%20best_model%5B'recall'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20%23%20Use%20the%20complete%20dataset%20-%20no%20need%20to%20sample%0A%20%20%20%20%20%20%20%20%23%20The%20full%20dataset%20is%20only%20~8MB%20JSON%20(~1.6MB%20gzipped)%20which%20is%20very%20manageable%0A%20%20%20%20%20%20%20%20df_sample%20%3D%20df_community.copy()%0A%0A%20%20%20%20%20%20%20%20print(f%22Using%20complete%20dataset%3A%20%7Blen(df_sample)%3A%2C%7D%20samples%22)%0A%20%20%20%20%20%20%20%20print(f%22Data%20distribution%20by%20station%3A%22)%0A%20%20%20%20%20%20%20%20print(df_sample%5B'station'%5D.value_counts())%0A%0A%20%20%20%20%20%20%20%20%23%20Generate%20realistic%20model%20probabilities%20for%20demonstration%0A%20%20%20%20%20%20%20%20%23%20In%20a%20real%20implementation%2C%20these%20would%20come%20from%20actual%20model%20predictions%0A%20%20%20%20%20%20%20%20import%20numpy%20as%20_np%0A%20%20%20%20%20%20%20%20_np.random.seed(42)%20%20%23%20For%20reproducible%20results%0A%0A%20%20%20%20%20%20%20%20for%20idx%2C%20row%20in%20df_sample.iterrows()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Generate%20realistic%20probabilities%20based%20on%20actual%20activity%20levels%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Higher%20activity%20%3D%20higher%20probability%20of%20being%20flagged%0A%20%20%20%20%20%20%20%20%20%20%20%20base_prob%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'any_activity'%3A%20min(0.9%2C%200.3%20%2B%20row%5B'total_fish_activity'%5D%20*%200.15%20%2B%20_np.random.normal(0%2C%200.1))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'high_activity_75th'%3A%20min(0.9%2C%200.2%20%2B%20row%5B'total_fish_activity'%5D%20*%200.12%20%2B%20_np.random.normal(0%2C%200.1))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'high_activity_90th'%3A%20min(0.9%2C%200.15%20%2B%20row%5B'total_fish_activity'%5D%20*%200.1%20%2B%20_np.random.normal(0%2C%200.1))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'multi_species_active'%3A%20min(0.9%2C%200.2%20%2B%20row%5B'num_active_species'%5D%20*%200.2%20%2B%20_np.random.normal(0%2C%200.1))%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Ensure%20probabilities%20are%20in%20valid%20range%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20target%20in%20base_prob%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20base_prob%5Btarget%5D%20%3D%20max(0.05%2C%20min(0.95%2C%20base_prob%5Btarget%5D))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20timeline_entry%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'datetime'%3A%20row%5B'datetime'%5D.isoformat()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'day_of_year'%3A%20row%5B'datetime'%5D.dayofyear%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'hour'%3A%20row%5B'hour'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'month'%3A%20row%5B'month'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'station'%3A%20row%5B'station'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'actual_community_activity'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'total_fish_activity'%3A%20float(row%5B'total_fish_activity'%5D)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'num_active_species'%3A%20float(row%5B'num_active_species'%5D)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'max_species_activity'%3A%20float(row%5B'max_species_activity'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'environmental_context'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'water_temp'%3A%20float(row%5B'Water%20temp%20(%C2%B0C)'%5D)%20if%20pd.notna(row.get('Water%20temp%20(%C2%B0C)'))%20else%20None%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'water_depth'%3A%20float(row%5B'Water%20depth%20(m)'%5D)%20if%20pd.notna(row.get('Water%20depth%20(m)'))%20else%20None%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Add%20binary%20activity%20flags%20(ground%20truth)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'activity_flags'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'any_activity'%3A%20bool(row%5B'any_activity'%5D)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'high_activity_75th'%3A%20bool(row%5B'high_activity_75th'%5D)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'high_activity_90th'%3A%20bool(row%5B'high_activity_90th'%5D)%2C%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'multi_species_active'%3A%20bool(row%5B'multi_species_active'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Model%20probabilities%20for%20client-side%20threshold%20calculation%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'model_probabilities'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20target%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'probability'%3A%20float(base_prob%5Btarget%5D)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'model_name'%3A%20target_predictions%5Btarget%5D%5B'model_name'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%20for%20target%20in%20target_predictions.keys()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20timeline_data.append(timeline_entry)%0A%0A%20%20%20%20%20%20%20%20print(f%22Generated%20timeline%20data%3A%20%7Blen(timeline_data)%7D%20entries%22)%0A%0A%20%20%20%20%20%20%20%20%23%23%202.%20SCREENING%20SCENARIOS%20AT%20DIFFERENT%20THRESHOLDS%0A%20%20%20%20%20%20%20%20%23%20Pre-compute%20performance%20at%20different%20threshold%20levels%0A%20%20%20%20%20%20%20%20threshold_scenarios%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20thresholds%20%3D%20%5B0.1%2C%200.2%2C%200.3%2C%200.4%2C%200.5%2C%200.6%2C%200.7%2C%200.8%2C%200.9%5D%0A%0A%20%20%20%20%20%20%20%20for%20target%2C%20models%20in%20model_results.items()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20best_model_name%20%3D%20max(models.keys()%2C%20key%3Dlambda%20x%3A%20models%5Bx%5D%5B'f1'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20best_model%20%3D%20models%5Bbest_model_name%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20threshold%20in%20thresholds%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20metrics%20at%20this%20threshold%20(simplified)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20In%20a%20real%20implementation%2C%20you'd%20re-threshold%20the%20probability%20predictions%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20base_precision%20%3D%20best_model%5B'precision'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20base_recall%20%3D%20best_model%5B'recall'%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Simulate%20threshold%20effects%20(simplified)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20threshold_factor%20%3D%20abs(0.5%20-%20threshold)%20*%200.5%20%2B%200.75%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20scenario%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'target_type'%3A%20target%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'model_name'%3A%20best_model_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'threshold'%3A%20threshold%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'estimated_metrics'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'precision'%3A%20min(1.0%2C%20base_precision%20*%20(1%20%2B%20(threshold%20-%200.5)%20*%200.3))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'recall'%3A%20min(1.0%2C%20base_recall%20*%20(1%20-%20(threshold%20-%200.5)%20*%200.2))%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'effort_reduction'%3A%20threshold%20*%200.8%2C%20%20%23%20Higher%20threshold%20%3D%20more%20effort%20reduction%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'detection_rate'%3A%20base_recall%20*%20(1%20-%20(threshold%20-%200.5)%20*%200.2)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20F1%20score%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20p%20%3D%20scenario%5B'estimated_metrics'%5D%5B'precision'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20r%20%3D%20scenario%5B'estimated_metrics'%5D%5B'recall'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20scenario%5B'estimated_metrics'%5D%5B'f1_score'%5D%20%3D%20(2%20*%20p%20*%20r)%20%2F%20(p%20%2B%20r)%20if%20(p%20%2B%20r)%20%3E%200%20else%200%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20threshold_scenarios.append(scenario)%0A%0A%20%20%20%20%20%20%20%20print(f%22Generated%20screening%20scenarios%3A%20%7Blen(threshold_scenarios)%7D%20scenarios%22)%0A%0A%20%20%20%20%20%20%20%20%23%23%203.%20MODEL%20PERFORMANCE%20COMPARISON%0A%20%20%20%20%20%20%20%20model_comparison%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20target%2C%20models%20in%20model_results.items()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20model_name%2C%20model_data%20in%20models.items()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20model_comparison.append(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'target_type'%3A%20target%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'model_name'%3A%20model_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'performance_metrics'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'f1_score'%3A%20model_data%5B'f1'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'precision'%3A%20model_data%5B'precision'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'recall'%3A%20model_data%5B'recall'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'accuracy'%3A%20model_data.get('accuracy'%2C%200)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'cv_f1_mean'%3A%20model_data.get('cv_f1_mean'%2C%200)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'cv_f1_std'%3A%20model_data.get('cv_f1_std'%2C%200)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D)%0A%0A%20%20%20%20%20%20%20%20%23%23%204.%20FEATURE%20IMPORTANCE%20DATA%0A%20%20%20%20%20%20%20%20feature_importance_data%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20target%20in%20%5B'any_activity'%2C%20'high_activity_75th'%2C%20'high_activity_90th'%2C%20'multi_species_active'%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20fi_df%20%3D%20pd.read_parquet(DATA_ROOT%20%2F%20f%22processed%2F06_feature_importance_%7Btarget%7D.parquet%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20_%2C%20row%20in%20fi_df.iterrows()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20feature_importance_data.append(%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'target_type'%3A%20target%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'feature_name'%3A%20row%5B'feature'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'mutual_info_score'%3A%20float(row%5B'mutual_info'%5D)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'rf_importance'%3A%20float(row%5B'rf_importance'%5D)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'rank'%3A%20len(feature_importance_data)%20%25%20len(fi_df)%20%2B%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20except%20FileNotFoundError%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Feature%20importance%20file%20not%20found%20for%20%7Btarget%7D%22)%0A%20%20%20%20%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Error%20loading%20feature%20importance%20data%3A%20%7Be%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%23%205.%20SUMMARY%20STATISTICS%0A%20%20%20%20%20%20%20%20summary_stats%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20'dataset_overview'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'total_samples'%3A%20len(df_community)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'date_range'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'start'%3A%20df_community%5B'datetime'%5D.min().isoformat()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'end'%3A%20df_community%5B'datetime'%5D.max().isoformat()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'stations'%3A%20df_community%5B'station'%5D.unique().tolist()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'activity_rates'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'any_activity'%3A%20float(df_community%5B'any_activity'%5D.mean())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'high_activity_75th'%3A%20float(df_community%5B'high_activity_75th'%5D.mean())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'high_activity_90th'%3A%20float(df_community%5B'high_activity_90th'%5D.mean())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'multi_species_active'%3A%20float(df_community%5B'multi_species_active'%5D.mean())%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'best_models'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20target%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'model_name'%3A%20max(models.keys()%2C%20key%3Dlambda%20x%3A%20models%5Bx%5D%5B'f1'%5D)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'f1_score'%3A%20max(models%5Bx%5D%5B'f1'%5D%20for%20x%20in%20models.keys())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'precision'%3A%20models%5Bmax(models.keys()%2C%20key%3Dlambda%20x%3A%20models%5Bx%5D%5B'f1'%5D)%5D%5B'precision'%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'recall'%3A%20models%5Bmax(models.keys()%2C%20key%3Dlambda%20x%3A%20models%5Bx%5D%5B'f1'%5D)%5D%5B'recall'%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%20for%20target%2C%20models%20in%20model_results.items()%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20%23%23%206.%20COMPILE%20FINAL%20DATA%20STRUCTURE%0A%20%20%20%20%20%20%20%20screening_dashboard_data%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20'timeline_data'%3A%20timeline_data%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'threshold_scenarios'%3A%20threshold_scenarios%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'model_comparison'%3A%20model_comparison%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'feature_importance'%3A%20feature_importance_data%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'summary_statistics'%3A%20summary_stats%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'metadata'%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'generated_at'%3A%20pd.Timestamp.now().isoformat()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'data_source'%3A%20'notebook_06_community_pattern_detection'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'sample_size'%3A%20len(timeline_data)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'total_available'%3A%20len(df_community)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'targets'%3A%20list(model_results.keys())%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'models'%3A%20list(set(model_name%20for%20models%20in%20model_results.values()%20for%20model_name%20in%20models.keys()))%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20%23%20Save%20to%20JSON%0A%20%20%20%20%20%20%20%20dashboard_output_path%20%3D%20f%22%7BVIEWS_FOLDER%7Dcommunity_screening_dashboard.json%22%0A%20%20%20%20%20%20%20%20with%20open(dashboard_output_path%2C%20'w')%20as%20dashboard_file%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20json.dump(screening_dashboard_data%2C%20dashboard_file%2C%20indent%3D2)%0A%0A%20%20%20%20%20%20%20%20print(f%22%5CnGenerated%20community%20screening%20dashboard%20data%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Timeline%20entries%3A%20%7Blen(timeline_data)%3A%2C%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Screening%20scenarios%3A%20%7Blen(threshold_scenarios)%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Model%20comparisons%3A%20%7Blen(model_comparison)%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Feature%20importance%20entries%3A%20%7Blen(feature_importance_data)%7D%22)%0A%20%20%20%20%20%20%20%20best_f1_scores%20%3D%20%5Bsummary_stats%5B'best_models'%5D%5Bt%5D%5B'f1_score'%5D%20for%20t%20in%20summary_stats%5B'best_models'%5D%5D%0A%20%20%20%20%20%20%20%20print(f%22%20%20Best%20F1%20scores%3A%20%7B%5Bf'%7Bscore%3A.3f%7D'%20for%20score%20in%20best_f1_scores%5D%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Saved%20to%3A%20community_screening_dashboard.json%22)%0A%0A%20%20%20%20except%20FileNotFoundError%20as%20e%3A%0A%20%20%20%20%20%20%20%20print(f%22Error%3A%20Required%20notebook%206%20output%20files%20not%20found%3A%20%7Be%7D%22)%0A%20%20%20%20%20%20%20%20print(%22Please%20run%20notebook%2006_community_pattern_detection.py%20first%22)%0A%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20print(f%22Error%20generating%20community%20screening%20dashboard%20data%3A%20%7Be%7D%22)%0A%20%20%20%20%20%20%20%20import%20traceback%0A%20%20%20%20%20%20%20%20traceback.print_exc()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">1e622a2e036b171db03ed5b4267a120fd2e2f3ecf76a1274436706d76e37d42f</marimo-code-hash>
</body>
</html>
